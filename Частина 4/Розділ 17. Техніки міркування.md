# Розділ 17: Техніки міркування

Техніки міркування в інтелектуальних системах - це методи, які покращують здатність агентів розв'язувати складні задачи через більш глибокі та систематичні мисленнєві процеси. На відміну від простого "генерувати та вибирати" підходу, ці техніки розділяють складні задачи на менші кроки, дозволяючи системам перевіряти свої міркування, коригувати помилки та розглядати кілька шляхів розв'язання паралельно.

Ми дослідимо кілька ключових методів, включаючи Chain-of-Thought (ланцюг думок), Tree-of-Thought (дерево думок), self-correction (самокорекція), Program-Aided Language Models (мовні моделі з програмною допомогою), ReAct (рассудження та дія), та інші передові техніки, які навколо оптимізації процесу рассудження та виведення коефіцієнтів масштабування.

## Практичні застосування та випадки використання

Практичні застосування включають:

- **Комплексні відповіді на питання:** Полегшення розв'язання багатокрокових запитів, які потребують інтеграції даних з різних джерел та виконання логічних висновків, потенційно включаючи дослідження кількох шляхів міркування та отримання користі від розширеного часу виведення для синтезу інформації.

- **Розв'язання математичних задач:** Забезпечення розділення математичних проблем на менші, розв'язні компоненти, ілюструючи покроковий процес, та використання виконання коду для точних розрахунків, де тривале виведення дозволяє складнішу генерацію та валідацію коду.

- **Відладка та генерація коду:** Підтримка пояснення агентом своїх міркувань для генерування або виправлення коду, виявлення потенційних проблем послідовно та ітеративного уточнення коду на основі результатів тестування (самокорекція), використовуючи розширений час виведення для ретельних циклів відладки.

- **Стратегічне планування:** Допомога в розробці комплексних планів через міркування про різні варіанти, наслідки та передумови та коригування планів на основі зворотного зв'язку в режимі реального часу (ReAct), де розширене обдумування може привести до більш ефективних та надійних планів.

- **Медична діагностика:** Допомога агенту в систематичній оцінці симптомів, результатів тестів та історії пацієнта для постановки діагнозу, артикулюючи свої міркування на кожному етапі та потенційно використовуючи зовнішні інструменти для отримання даних (ReAct). Збільшений час виведення дозволяє більш комплексну диференційну діагностику.

- **Правовий аналіз:** Підтримка аналізу правових документів та прецедентів для формулювання аргументів або надання рекомендацій, деталізуючи здійснені логічні кроки та забезпечуючи логічну узгодженість через самокорекцію. Збільшений час виведення дозволяє більш глибокі правові дослідження та побудову аргументів.

## Техніки міркування

Для початку давайте глибше розберемося в основних техніках міркування, що використовуються для поліпшення здатностей розв'язання проблем AI-моделей.

**Chain-of-Thought (CoT)** промптинг значно покращує здатності складних міркувань LLM, імітуючи покроковий процес мислення (див. Рис. 1). Замість надання прямої відповіді, CoT промпти направляють модель до генерування послідовності проміжних кроків міркування. Це явне розділення дозволяє LLM справляти зі складними проблемами, розкладаючи їх на менші, більш керовані підпроблеми. Ця техніка помітно покращує продуктивність моделі на завданнях, які вимагають багатокрокових міркувань, таких як арифметика, міркування здорового глузду та символічні маніпуляції.

Основна перевага CoT - його здатність трансформувати складну, одноступеневу проблему в серію більш простих кроків, тим самим збільшуючи прозорість процесу міркування LLM. Цей підхід не тільки підвищує точність, але також пропонує цінні розуміння ухвалення рішень моделлю, допомагаючи в відладці та розумінні.

CoT може бути реалізований із використанням різних стратегій, включаючи надання прикладів few-shot, які демонструють покрокові міркування, або просто інструктування моделі "думати покроково". Його ефективність проистекает з його здатності направляти внутрішню обробку моделі до більш продуманого та логічного прогресу. В результаті Chain-of-Thought став найважливішою техніою для забезпечення передових можливостей міркування в сучасних LLM. Ця покращена прозорість та розділення складних проблем на керовані підпроблеми особливо важливі для автономних агентів, оскільки дозволяють їм виконувати більш надійні та перевірні дії в складних середовищах.

![][image2]

Рис. 1: CoT промпт разом із деталізованою, поступовою відповіддю, створеною агентом.

Давайте розглянемо приклад. Він починається з набору інструкцій, які кажуть AI, як думати, визначаючи його персону та ясний п'ятикроковий процес для дотримання. Це промпт, який ініціює структуроване мислення.

Слідуючи цьому, приклад показує процес CoT в дії. Розділ, позначений "Мисленнєвий процес агента", є внутрішнім монологом, де модель виконує інструійовані кроки. Це буквально "ланцюжок думок". Нарешті, "Остаточна відповідь агента" - це відполірована, комплексна відповідь, створена в результаті цього ретельного, покрокового процесу міркування.

```
Ви - агент пошуку інформації. Ваша мета - відповідати на питання користувача вичерпно та точно, думаючи покроково.

Ось процес, якого ви повинні дотримуватися:

1. **Аналіз запиту:** Зрозумійте основну тему та конкретні вимоги питання користувача. Визначте ключові сутності, ключові слова та тип інформації, яку шукають.

2. **Формулювання пошукових запитів (для бази знань):** На основі вашого аналізу сгенеруйте список точних пошукових запитів, які ви б використовували для отримання релевантної інформації з бази знань або зовнішніх інструментів.

3. **Симуляція пошуку інформації (самокорекція/міркування):** Для кожного пошукового запиту мисленно розглянути, які дані ви очікуєте знайти. Якби ви отримали вміст, які б були найбільш релевантні уривки? Подумайте про потенційні неоднозначності або відсутні частини.



Chain-of-Thought (CoT) побудована на спостереженні, що великі мовні моделі (LLM) часто помиляються при прямому вирішенні складних завдань. На місцевому цьому, якщо попросити LLM показати свої рассудження "крок за кроком", точність часто значно покращується, інколи подвійне збільшення.

Основна ідея просто: замість того, щоб попросити модель дати безпосередню відповідь, ви просите її показати кожний логічний крок до цієї відповіді. Наприклад:

```
Запит: Марія купила 5 яблук. Потім вона купила ще 3. Скільки яблук у неї є?

Промпт без CoT:
"Скільки яблук у Марії?"

Відповідь моделі: (часто помилкова, просто число)

Промпт з CoT:
"Марія купила 5 яблук. Потім вона купила ще 3. Покажіть свої кроки рассудження для знаходження загальної кількості яблук."

Відповідь моделі:
1. Спочатку Марія купила 5 яблук
2. Потім вона купила ще 3 яблука
3. Загалом: 5 + 3 = 8 яблук
4. Отже, у Марії є 8 яблук.
```

Це простий, але потужний підхід. Еволюція CoT за цим простим принципом включає кілька варіацій:

- **Few-shot CoT:** Забезпечення кількох приклад задачі та їхніх рассудень допомагає моделі краще розуміти очікуваний формат.
- **Zero-shot CoT:** Замість явного надання прикладів, ви просто запрошуєте: "Давайте подумаємо крок за кроком" - часто дає вдивовижні результати.
- **Automatic CoT:** Системи можуть автоматично генерувати рацыґа рассудження для навчальних прикладів без ручного кураціювання.

## Tree-of-Thought (дерево думок)

Tree-of-Thought (ToT) розширює CoT, дозволяючи моделям не просто думати лінійно, а розглядати кілька можливих шляхів мислення паралельно, як дерево можливостей.

Уявіть собі, що ви намагаєтесь розв'язати складну головоломку. Ви можете почати з однієї гіпотези, але якщо наткнетесь на кінець, можете повернутися (backtrack) і спробувати інший шлях. ToT дозволяє LLM робити саме це:

1. **Генерація кандидатів:** Модель генерує кілька можливих "наступних кроків" або "проміжних висновків".
2. **Оцінка:** Кожний кандидат оцінюється так, щоб визначити, який шлях найбільш перспективний.
3. **Розширення дерева:** Найбільш обіцяючі шляхи розширюються далі, створюючи розгалужене дерево можливостей.
4. **Пошук найкращого шляху:** Система навігує цим деревом для знаходження оптимального розв'язання.

Цей підхід особливо ефективний при вирішенні:
- Проблем з кількома правильними рішеннями
- Задач, що вимагають ретельного планування
- Сценаріїв, де рішення залежать від обраного шляху

## Self-Correction (самокорекція)

Self-Correction дозволяє LLM виявляти помилки у своїх відповідях та коригувати їх. Цей підхід включає:

1. **Генерація першого чернетки:** Модель генерує первісну відповідь.
2. **Самооцінка:** Модель аналізує свою відповідь на предмет помилок або недостатків.
3. **Корекція:** Якщо помилки виявлені, модель інтегрує зворотний зв'язок та генерує покращену версію.

Приклад:

```
Перша спроба:
"Квадрат 15 дорівнює 200"

Самооцінка:
"Дозвольте мне перевірити: 15 × 15 = 225, не 200. Я допустив помилку."

Коригована відповідь:
"Квадрат 15 дорівнює 225"
```

## Program-Aided Language Models (PALM)

Program-Aided Language Models поєднують LLM з можливістю виконання коду. На лівом PALM LLM обробляє задачу, але замість того, щоб робити все чисельні розрахунки в своїй "голові", вона генерує програмний код, який потім виконується для отримання точного результату.

Наприклад:

```
Задача: Если x = 5, y = 3, и z = x² + y³, якого значення z?

LLM генерує Python код:
x = 5
y = 3
z = x**2 + y**3
print(z)

Код виконується:
Результат: z = 52
```

PALM особливо корисна для:
- Математичних розрахунків
- Логічних операцій
- Маніпуляцій з даними
- Симуляцій

## ReAct (Reasoning + Acting)

ReAct поєднує рассудження з дійснісною дією. Замість того, щоб спочатку подумати про весь розв'язок та потім виконати його, агент чергує думки та дії:

**Цикл Thought-Action-Observation:**
1. **Thought (думка):** Агент рефлексує над проблемою та планує наступну дію.
2. **Action (дія):** Агент виконує конкретну дію (наприклад, викликає функцію, шукає інформацію).
3. **Observation (спостереження):** Агент спостерігає результат дії.
4. **Цикл повторюється** поки проблема не розв'язана.

Приклад ReAct цикл для інформаційного запиту:

```
Запит: Хто був президентом США в 1990?

Thought: Мені потрібна історична інформація про американських президентів.
Action: search("president of USA 1990")
Observation: В 1990 році президентом США був Джордж Буш (старший).

Thought: Я отримав чітку відповідь.
Action: return("George H.W. Bush")
```

ReAct дозволяє агентам:
- Динамічно адаптуватися до нових інформацій
- Коригувати свій маршрут, якщо дія не дала очікуваного результату
- Взаємодіяти з зовнішніми системами та інструментами

## Reinforcement Learning with Verifiable Rewards (RLVR)

RLVR представляє підхід до навчання спеціалізованих моделей для складних рассудження задач. Замість навчання на всій популяції наслідків, система навчається на основі верифікованих, конкретних результатів.

Процес:

1. **Генерація розв'язків:** Модель генерує кандидатів розв'язання для складної задачи.
2. **Верифікація:** Кожне рішення перевіряється на предмет коректності (наприклад, автоматизована перевірка).
3. **Винагородження:** Моделі, які генерують верифіковані правильні рішення, отримують винагороди.
4. **Навчання:** Модель навчається вддосконалювати свої рассудження на основі цих винагород, поступово вдосконалюючи точність на складних задачах.

Це особливо корисно для:
- Математичних доказів
- Програмної генерації та синтезу
- Наукових гіпотез та висновків
- Складних логічних проблем

## Chain of Debates (CoD)

Chain of Debates модифікує дебатний процес, де кілька AI-моделей приймають різні позиції та аргументують їхнім, як живий дебат:

1. **Постановка питання:** Питання або проблема вкладається обговорення.
2. **Позиції:** Кожна AI-модель приймає певну позицію або перспективу.
3. **Аргументація:** Кожна модель висуває аргументи на підтримку своєї позиції.
4. **Контрапозиції:** Інші моделі надають контрапозиції.
5. **Консенсус:** После кількох раундів обговорення, система намагається досягти консенсусу чи визначити найсильніші аргументи.

Приклад:

```
Питання: Чи варто компаніям запровадити 4-денний робочий тиждень?

AI-модель А (За): "4-денний робочий тиждень підвищує продуктивність, оскільки...
AI-модель B (Проти): "Однак це створює проблеми для кліієнтів, оскільки..."
AI-модель C (Нейтральна): "Насправді, дані показують, що обидва підходи мають...
```

## Graph of Debates (GoD)

Graph of Debates розширює Chain of Debates до більш складної, нелінійної структури. На місцевому цьому, замість послідовного обговорення, дебати організовані як граф, де кілька обговорень можуть розгалужуватися та сходитися:

1. **Вузли графа:** Кожний вузол являє собою конкретну точку зору або аргумент.
2. **Ребра:** З'єднання між вузлами показують, як аргументи пов'язані або суперечать один одному.
3. **Динамічне розширення:** Граф може динамічно розширюватися з новими вузлами, коли приходять нові аргументи.
4. **Пошук консенсусу:** Система анализує весь граф для знаходження консенсусного рішення або найсильнішого набору аргументів.

GoD особливо корисна для:
- Складних багатовимірних проблем
- Сценаріїв з конкуруючими інтересами
- Аналізу системи, що вимагають розгляду багатьох перспектив

## MASS (Multi-Agent System Search)

MASS (Multi-Agent System Search) оптимізує взаємодію між агентами на трьох рівнях:

1. **Prompt-level:** Оптимізація промптів, які надсилаються агентам.
2. **Topology-level:** Оптимізація структури взаємодії між агентами (наприклад, послідовні, паралельні, навколо деревовидна структура).
3. **Workflow-level:** Оптимізація загального процесу роботи системи.

На кожному рівні система ітеративно покращує конфігурацію для досягнення найбільш ефективного набору міжагентних взаємодій.

## Закони масштабування виведення (Inference Scaling Laws)

Один з найбільш захоплюючих открытий останніх років - це така звана закон масштабування виведення: більше обчислювальних ресурсів, витрачених під час виведення, часто призводить до значно кращих результатів, навіть якщо модель потрібної розробляється не поклась більше.

Наприклад, замість однієї спроби відповісти на питання, модель може:
- Генерувати кілька версій відповіді
- Оцінювати та порівнювати їх
- Вибирати найкращу

Обчислювальні витрати на це роблять набагато більше, ніж простий однопроходовий перевід, але результати часто значно кращі.

Це вело до виникнення нових моделей, як o1 OpenAI, які опрацьовують значно більше часу на рассудження перед генеруванням відповіді. Ці моделі демонструють, що масштабування виведення може привести до масштабування мислення якості.

## Deep Research та автономне розслідування

Deep Research являє собою практичне застосування безлічі техник рассудження за єдиною, простою в використанні парадигмою: агент повинен провести глибоке дослідження на задану тему.

Deep Research спочатку розбиває запит користувача на безліч підзапитів, а потім ітеративно:
1. Проводить дослідження на вищому рівні
2. Генерує гіпотези
3. Виявляє гапи у знаннях
4. Перевіряє та уточнює раніше зроблені висновки

На кожній ітерації, система вдосконалює своє розуміння теми, поступово будуючи все більш всеохоплюючу та правильну модель проблеми.

Далі наведено практичний приклад імплементації Deep Research за допомогою LangGraph, який заснований на цих техніках рассудження:

```python
from langgraph.graph import StateGraph
from langchain_core.messages import HumanMessage, AIMessage
from langchain_google_genai import ChatGoogleGenerativeAI

# Ініціалізація LangGraph
model = ChatGoogleGenerativeAI(model="gemini-pro")

# Визначення станів для Deep Research
class ResearchState:
    user_query: str
    sub_queries: list
    research_results: dict
    refined_hypothesis: str

# Вузол: Розбиття запиту
def break_down_query(state: ResearchState):
    response = model.invoke([HumanMessage(content=f"Розбийте цей запит на підзапити: {state.user_query}")])
    state.sub_queries = response.content.split("\n")
    return state

# Вузол: Проведення дослідження
def conduct_research(state: ResearchState):
    results = {}
    for query in state.sub_queries:
        response = model.invoke([HumanMessage(content=f"Дослідіть: {query}")])
        results[query] = response.content
    state.research_results = results
    return state

# Вузол: Рефлексія та уточнення
def reflect_and_refine(state: ResearchState):
    all_findings = "\n".join([f"{q}: {r}" for q, r in state.research_results.items()])
    response = model.invoke([
        HumanMessage(content=f"На основі цих знахідок: {all_findings}. Який найбільш узгоджений висновок?")
    ])
    state.refined_hypothesis = response.content
    return state

# Побудова графа
graph = StateGraph(ResearchState)
graph.add_node("break_down", break_down_query)
graph.add_node("research", conduct_research)
graph.add_node("reflect", reflect_and_refine)

graph.add_edge("break_down", "research")
graph.add_edge("research", "reflect")
graph.set_entry_point("break_down")
graph.set_finish_point("reflect")

# Компіляція та запуск
compiled_graph = graph.compile()

# Приклад використання
initial_state = ResearchState(
    user_query="Яка роль штучного інтелекту в сучасній медицині?",
    sub_queries=[],
    research_results={},
    refined_hypothesis=""
)

result = compiled_graph.invoke(initial_state)
print("Остаточний висновок:", result.refined_hypothesis)
```

## Закон масштабування виведення (Inference Scaling Laws)

Один з найбільш захоплюючих открытий останніх років - це така звана закон масштабування виведення: більше обчислювальних ресурсів, витрачених під час виведення, часто призводить до значно кращих результатів, навіть якщо модель потрібної розробляється не поклась більше.

Наприклад, замість однієї спроби відповісти на питання, модель може:
- Генерувати кілька версій відповіді
- Оцінювати та порівнювати їх
- Вибирати найкращу

Обчислювальні витрати на це роблять набагато більше, ніж простий однопроходовий перевід, але результати часто значно кращі.

Це вело до виникнення нових моделей, як o1 OpenAI, які опрацьовують значно більше часу на рассудження перед генеруванням відповіді. Ці моделі демонструють, що масштабування виведення може привести до масштабування мислення якості.

## Deep Research та автономне розслідування

Deep Research являє собою практичне застосування безлічі техник рассудження за єдиною, простою в використанні парадигмою: агент повинен провести глибоке дослідження на задану тему.

Deep Research спочатку розбиває запит користувача на безліч підзапитів, а потім ітеративно:
1. Проводить дослідження на вищому рівні
2. Генерує гіпотези
3. Виявляє гапи у знаннях
4. Перевіряє та уточнює раніше зроблені висновки

На кожній ітерації система вдосконалює своє розуміння теми, поступово будуючи все більш всеохоплюючу та правильну модель проблеми.

## Практичні застосування та вибір техніки

Вибір техніки рассудження залежить від типу задачі:

- **Chain-of-Thought (CoT):** Ідеально для логічних та математичних задач, де послідовні кроки критичні.
- **Tree-of-Thought (ToT):** Краще для комбінаторних задач або сценаріїв з багатьма можливими шляхами.
- **Self-Correction:** Ефективна для ітеративних уточнень та коригування помилок.
- **PALM:** Незамінима для точних розрахунків та логічних операцій.
- **ReAct:** Найкращий вибір для агентів, що мають взаємодіяти з зовнішніми системами та інструментами.
- **RLVR:** Ідеально для спеціалізованих моделей, навчених на верифікованих результатах.
- **CoD/GoD:** Ефективні для багатовимірних аналізів та досягнення консенсусу.
- **MASS:** Для оптимізації складних багатоагентних систем.
- **Deep Research:** Ідеально для всебічного вивчення комплексних тем.

## Дуже коротко

**Що:** Техники рассудження включають набір методів для вдосконалення здатності великих мовних моделей розв'язувати складні задачи. На місцевому цьому, задачи часто розбиваються на менші логічні кроки або розглядаються через кілька альтернативних перспектив. Через це, лами моделі можуть краще аналізувати, коригувати помилки та досягати більш точних результатів.

**Чому:** Мовні моделі часто помиляються при прямому вирішенні складних завдань. Однак коли їх просять показати своє рассудження крок за кроком, точність часто значно покращується. Чим більше стратегічних кроків рассудження, тим точніше результат. Деякі техніки включають виконання реального кода (PALM), взаємодію з інструментами та зовнішніми системами (ReAct), або розглядання безлічі можливих шляхів паралельно (ToT). Кожна техніка має свої переваги та випадки використання.

**Практичне правило:** Виберіть техніку рассудження на основі типу задачі. Для послідовних логічних задач використовуйте CoT. Для комбінаторних проблем або багатошляховго вибору розглядайте ToT. Коли агент повинен взаємодіяти з інструментами та мати зворотний зв'язок, використовуйте ReAct. Для високоточних розрахунків та програмної генерації комбінуйте з PALM. Для дослідження комплексних тем використовуйте Deep Research.

## Ключові висновки

- **Chain-of-Thought поліпшує точність:** Просто попросивши моделі показати своє рассудження крок за кроком, часто подвоюється точність.
- **Tree-of-Thought дозволяє паралельне дослідження:** Замість лінійного мислення, модель може розглядати кілька шляхів одночасно.
- **Self-Correction забезпечує ітеративне вдосконалення:** Моделі можуть перевіряти свої відповіді та коригувати помилки.
- **Program-Aided Models забезпечують точність:** Комбінація LLM з виконанням коду гарантує точні розрахунки.
- **ReAct інтегрує рассудження та дію:** Чергування думок та дій дозволяє динамічну адаптацію та взаємодію з інструментами.
- **RLVR створює спеціалізовані моделі:** Модель навчається на верифікованих розв'язаннях для розвитку глибокого рассудження.
- **Chain of Debates та Graph of Debates сприяють багатовимірному аналізу:** Кілька перспектив можуть бути розглянуті та порівняні для досягнення консенсусу.
- **MASS оптимізує багатоагентні взаємодії:** Оптимізація промптів, топології та робочого процесу покращує ефективність.
- **Закони масштабування виведення підтримують більш глибоке рассудження:** Більшої обчислювальних ресурсів на виведення часто призводить до значно кращих результатів.
- **Deep Research являє практичне застосування:** Поєднання безлічі техніки для всебічного дослідження комплексних тем.

## Висновки

Техники рассудження - це могутні інструменти, які трансформують роботу великих мовних моделей, дозволяючи їм вирішувати складні проблеми більш методично та правильно. Від простого Chain-of-Thought до складних багатоагентних систем, кожна техніка робить значний внесок у розвиток штучного інтелекту. Коли правильно застосовані, ці техніки не тільки підвищують точність і надійність, але й дозволяють системам адаптуватися, вчитися та вдосконалюватися з часом. Вибір правильної техніки для кожної задачи - це ключ до побудови інтелектуальних систем наступного покоління.

## Література

1. Wei, J., et al. (2022). "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models." ArXiv:2201.11903
2. Yao, S., et al. (2024). "Tree of Thoughts: Deliberate Problem Solving with Large Language Models." ArXiv:2305.10601
3. Google DeepMind. "AlphaCode: Competition-level code generation with AlphaCode." 2022
4. Shinn, N., et al. (2024). "Reflexion: Language Agents with Verbal Reinforcement Learning." ArXiv:2303.11366
5. Yao, S., et al. (2023). "ReAct: Synergizing Reasoning and Acting in Language Models." ArXiv:2210.03629
6. OpenAI. "o1: Reasoning Models." 2024
7. LangGraph Documentation: https://langchain-ai.github.io/langgraph/
8. Google Generative AI: https://aistudio.google.com/

---

## Навігація

**Назад:** [Розділ 16. Оптимізація з урахуванням ресурсів](Розділ%2016.%20Оптимізація%20з%20урахуванням%20ресурсів.md)<br>
**Вперед:** [Розділ 18. Паттерни безпеки та захисні механізми](Розділ%2018.%20Паттерни%20безпеки.md)
