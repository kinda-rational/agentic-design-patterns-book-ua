# Розділ 19: Оцінка та моніторинг

Даний розділ розглядає методології, які дозволяють інтелектуальним агентам систематично оцінювати свою продуктивність, відслідковувати прогрес у досягненні цілей та виявляти операційні аномалії. Хоча розділ 11 описує постановку цілей та моніторинг, а розділ 17 розглядає механізми міркування, цей розділ сосередоджується на безперервному, часто зовнішньому, вимірюванні ефективності агента, його продуктивності та відповідності вимогам. Це включає визначення метрик, встановлення циклів зворотного зв'язку та впровадження систем звітування для забезпечення того, щоб продуктивність агента відповідала очікуванням у операційних середовищах (див. рис. 1).

![][image1]

Рис. 1. Найкращі практики для оцінки та моніторингу

# Практичні застосування та варіанти використання

Найпоширеніші застосування та варіанти використання:

- **Відслідковування продуктивності у живих системах:** Безперервний моніторинг точності, затримки та споживання ресурсів агента, розгорнутого у виробничому середовищі (наприклад, показник розв'язання проблем чат-бота служби підтримки клієнтів, час відклику).

- **A/B тестування для вдосконалення агентів:** Систематичне порівняння продуктивності різних версій агентів або стратегій паралельно для виявлення оптимальних підходів (наприклад, тестування двох різних алгоритмів планування для логістичного агента).

- **Аудити відповідності та безпеки:** Генерація автоматичних звітів аудиту, які відслідковують відповідність агента етичним рекомендаціям, нормативним вимогам та протоколам безпеки з часом. Ці звіти можуть бути перевірені людиною в контурі або іншим агентом, і можуть генерувати KPI або запускати попередження при виявленні проблем.

- **Корпоративні системи:** Для управління Agentic AI у корпоративних системах необхідний новий інструмент контролю - AI "Контракт". Це динамічне узгодження кодифікує цілі, правила та засоби контролю для завдань, делегованих AI.

- **Виявлення дрейфу:** Моніторинг релевантності або точності вихідних даних агента з часом, виявлення випадків, коли його продуктивність погіршується через зміни в розподілі вхідних даних (концептуальний дрейф) або зміни в навколишньому середовищі.

- **Виявлення аномалій у поведінці агента:** Виявлення незвичайних або неочікуваних дій, які вживає агент, які можуть указувати на помилку, шкідливу атаку або небажаний емерджентний розвиток.

- **Оцінка прогресу навчання:** Для агентів, призначених для навчання, відслідковування їхної кривої навчання, вдосконалення конкретних навичок або здатності до узагальнення на різних завданнях або наборах даних.

# Практичний приклад коду

Розробка комплексної системи оцінки для AI агентів являє собою складну задачу, порівняну за складністю з академічною дисципліною або значною публікацією. Ця складність випливає з численних факторів, які необхідно враховувати, таких як продуктивність моделі, взаємодія з користувачем, етичні наслідки та ширший суспільний вплив. Тим не менше, для практичної реалізації фокус можна звузити до критичних варіантів використання, необхідних для ефективного та результативного функціонування AI агентів.

**Оцінка відповідей агента:** Цей основний процес необхідний для оцінки якості та точності вихідних даних агента. Він включає визначення того, чи надає агент релевантну, коректну, логічну, неупереджену та точну інформацію у відповідь на задані вхідні дані. Метрики оцінки можуть включати фактичну коректність, бігань, граматичну точність та відповідність передбачуваній меті користувача.

```python
def evaluate_response_accuracy(agent_output: str, expected_output: str) -> float:
    """Обчислює просту оцінку точності для відповідей агента."""
    # Це дуже базове точне збігання; у реальному світі використовувалися б складніші метрики
    return 1.0 if agent_output.strip().lower() == expected_output.strip().lower() else 0.0


# Приклад використання
agent_response = "Столиця Франції - Париж."
ground_truth = "Париж є столицею Франції."
score = evaluate_response_accuracy(agent_response, ground_truth)
print(f"Точність відповіді: {score}")
```

Python функція `evaluate_response_accuracy` обчислює базову оцінку точності для відповіді AI агента, виконуючи точне порівняння без урахування регістру між вихідними даними агента та очікуваними вихідними даними після видалення провідних або кінцевих пробілів. Вона повертає оцінку 1.0 для точного збігання та 0.0 в іншому випадку, представляючи бінарну оцінку правильно/неправильно. Цей метод, хоча й прямолінійний для простих перевірок, не враховує варіації, такі як перефразування або семантична еквівалентність.

Проблема полягає в методі порівняння. Функція виконує суворе, символ за символом порівняння двох рядків. У наведеному прикладі:

- agent_response: "Столиця Франції - Париж."
- ground_truth: "Париж є столицею Франції."

Навіть після видалення пробілів та перетворення у нижній регістр ці два рядки не ідентичні. В результаті функція неправильно повертає оцінку точності `0.0`, навіть якщо обидва речення передають однаковий сенс.

Прямолінійне порівняння не справляється з оцінкою семантичної подібності, успішно працюючи лише якщо відповідь агента точно відповідає очікуваному результату. Більш ефективна оцінка вимагає передових технік обробки природної мови (NLP) для розрізнення смислу між реченнями. Для ретельної оцінки AI агентів у реальних сценаріях часто необхідні складніші метрики. Ці метрики можуть включати міри подібності рядків, такі як відстань Левенштейна та подібність Жаккара, аналіз ключових слів на присутність або відсутність конкретних ключових слів, семантичну подібність з використанням косинусної подібності з моделями вкладень, оцінками LLM-as-a-Judge (обговорювані далі для оцінки нюансованої коректності та корисності) та RAG-специфічними метриками, такими як вірність та релевантність.

**Моніторинг затримки:** Моніторинг затримки для дій агента має вирішальне значення в додатках, де швидкість відповіді або дії AI агента є критичним фактором. Цей процес вимірює тривалість, необхідну агенту для обробки запитів і генерування вихідних даних. Підвищена затримка може негативно впливати на досвід користувача та загальну ефективність агента, особливо в режимі реального часу або інтерактивних середовищах. У практичних застосуваннях простий вивід даних затримки у консоль недостатній. Рекомендується логування цієї інформації в постійну систему зберігання. Варіанти включають структуровані файли журналів (наприклад, JSON), бази даних часових рядів (наприклад, InfluxDB, Prometheus), сховища даних (наприклад, Snowflake, BigQuery, PostgreSQL) або платформи спостережуваності (наприклад, Datadog, Splunk, Grafana Cloud).

**Відслідковування використання жетонів для взаємодій LLM:** Для агентів, що працюють на LLM, відслідковування використання жетонів має вирішальне значення для управління витратами та оптимізації розподілу ресурсів. Біллінг для взаємодій LLM часто залежить від кількості оброблених жетонів (вхідних та вихідних). Тому ефективне використання жетонів безпосередньо знижує операційні витрати. Крім того, моніторинг кількості жетонів допомагає виявити потенційні області для вдосконалення у процесах prompt engineering або генерування відповідей.

```python
# Це концептуально, оскільки фактичний підрахунок жетонів залежить від LLM API
class LLMInteractionMonitor:
    def __init__(self):
        self.total_input_tokens = 0
        self.total_output_tokens = 0

    def record_interaction(self, prompt: str, response: str):
        # У реальному сценарії використовуйте лічильник жетонів LLM API або токенізатор
        input_tokens = len(prompt.split())  # Заглушка
        output_tokens = len(response.split())  # Заглушка
        self.total_input_tokens += input_tokens
        self.total_output_tokens += output_tokens
        print(f"Записано взаємодію: Вхідні жетони={input_tokens}, Вихідні жетони={output_tokens}")

    def get_total_tokens(self):
        return self.total_input_tokens, self.total_output_tokens


# Приклад використання
monitor = LLMInteractionMonitor()
monitor.record_interaction("Яка столиця Франції?", "Столиця Франції - Париж.")
monitor.record_interaction("Розкажи жарт.", "Чому вчені не довіряють атомам? Тому що вони все вигадують!")
input_t, output_t = monitor.get_total_tokens()
print(f"Всього вхідних жетонів: {input_t}, Всього вихідних жетонів: {output_t}")
```

Цей розділ представляє концептуальний Python клас `LLMInteractionMonitor`, розроблений для відслідковування використання жетонів у взаємодіях з великими мовними моделями. Клас включає лічильники як для вхідних, так і для вихідних жетонів. Його метод `record_interaction` імітує підрахунок жетонів, розділяючи рядки промпта та відповіді. У практичній реалізації використовувалися б конкретні токенізатори LLM API для точного підрахунку жетонів. У міру виникнення взаємодій монітор накопичує загальну кількість вхідних та вихідних жетонів. Метод `get_total_tokens` забезпечує доступ до цих накопичених підсумків, необхідних для управління витратами та оптимізації використання LLM.

**Користувальницька метрика для "корисності" з використанням LLM-as-a-Judge:** Оцінка суб'єктивних якостей, таких як "корисність" AI агента, представляє виклики, що виходять за рамки стандартних об'єктивних метрик. Потенційна система включає використання LLM як оцінювача. Цей підхід LLM-as-a-Judge оцінює вихідні дані іншого AI агента на основі заздалегідь визначених критеріїв "корисності". Використовуючи передові лінгвістичні здібності LLM, цей метод пропонує нюансовані, подібні до людини оцінки суб'єктивних якостей, що перевищують просте збігання ключових слів або оцінки на основі правил. Хоча ця техніка все ще розробляється, вона показує перспективи для автоматизації та масштабування якісних оцінок.

```python
import google.generativeai as genai
import os
import json
import logging
from typing import Optional

# --- Конфігурація ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Встановіть ваш ключ API як змінну оточення для запуску цього скрипту
# Наприклад, у вашому терміналі: export GOOGLE_API_KEY='your_key_here'
try:
    genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
except KeyError:
    logging.error("Помилка: змінна оточення GOOGLE_API_KEY не встановлена.")
    exit(1)

# --- Рубрика LLM-as-a-Judge для якості правових опитувань ---
LEGAL_SURVEY_RUBRIC = """
Ви експерт з методології правових опитувань та критичний правовий рецензент. Ваше завдання - оцінити якість поданого питання правового опитування.

Надайте оцінку від 1 до 5 за загальну якість разом з детальним обґрунтуванням та конкретним зворотним зв'язком.
Сосередоточтеся на наступних критеріях:

1. **Ясність та точність (Оцінка 1-5):**
   * 1: Виключно розпливчасто, дуже двозначно або заплутано.
   * 3: Помірно ясно, але могло б бути точнішим.
   * 5: Абсолютно ясно, однозначно та точно у правовій термінології (якщо застосовується) та намірі.

2. **Нейтральність та упередженість (Оцінка 1-5):**
   * 1: Сильно наводячи або упереджено, явно впливаючи на респондента до конкретної відповіді.
   * 3: Дещо суггестивно або може бути інтерпретовано як наводяче.
   * 5: Повністю нейтрально, об'єктивно та вільно від будь-якої наводячої мови або завантажених термінів.

3. **Релевантність та фокус (Оцінка 1-5):**
   * 1: Не стосується задекларованої теми опитування або виходить за межі.
   * 3: Слабко пов'язано, але могло б бути більш сфокусованим.
   * 5: Безпосередньо стосується цілей опитування та добре сфокусовано на одній концепції.

4. **Повнота (Оцінка 1-5):**
   * 1: Пропускає критичну інформацію, необхідну для точної відповіді, або надає недостатній контекст.
   * 3: В основному повна, але відсутні неважливі деталі.
   * 5: Надає весь необхідний контекст та інформацію для респондента, щоб дати повну відповідь.

5. **Відповідність аудиторії (Оцінка 1-5):**
   * 1: Використовує жаргон, недоступний цільовій аудиторії, або надмірно спрощений для експертів.
   * 3: В цілому відповідний, але деякі терміни можуть бути складними або спрощеними.
   * 5: Ідеально адаптований до передбачуваних правових знань та досвіду цільової аудиторії опитування.

**Формат виводу:**
Ваша відповідь ПОВИННА бути JSON об'єктом з такими ключами:
* `overall_score`: Ціле число від 1 до 5 (середня оцінка критеріїв або ваше цілісне судження).
* `rationale`: Коротке резюме, чому була дана ця оцінка, виділяючи основні сильні та слабкі сторони.
* `detailed_feedback`: Список у вигляді маркерів, деталізуючий зворотний зв'язок по кожному критерію (Ясність, Нейтральність, Релевантність, Повнота, Відповідність аудиторії). Запропонуйте конкретні вдосконалення.
* `concerns`: Список будь-яких конкретних правових, етичних або методологічних проблем.
* `recommended_action`: Коротка рекомендація (наприклад, "Переглянути для нейтральності", "Схвалити як є", "Уточнити область").
"""


class LLMJudgeForLegalSurvey:
    """Клас для оцінки питань правових опитувань з використанням генеративної AI моделі."""

    def __init__(self, model_name: str = 'gemini-1.5-flash-latest', temperature: float = 0.2):
        """
        Ініціалізує LLM Judge.

        Args:
            model_name (str): Назва моделі Gemini для використання.
                             'gemini-1.5-flash-latest' рекомендується для швидкості та вартості.
                             'gemini-1.5-pro-latest' пропонує найвищу якість.
            temperature (float): Температура генерації. Нижча краще для детерміністичної оцінки.
        """
        self.model = genai.GenerativeModel(model_name)
        self.temperature = temperature

    def _generate_prompt(self, survey_question: str) -> str:
        """Конструює повний промпт для LLM судді."""
        return f"{LEGAL_SURVEY_RUBRIC}\n\n---\n**ПИТАННЯ ПРАВОВОГО ОПИТУВАННЯ ДЛЯ ОЦІНКИ:**\n{survey_question}\n---"

    def judge_survey_question(self, survey_question: str) -> Optional[dict]:
        """
        Судить якість одного питання правового опитування з використанням LLM.

        Args:
            survey_question (str): Питання правового опитування для оцінки.

        Returns:
            Optional[dict]: Словник, що містить судження LLM, або None при помилці.
        """
        full_prompt = self._generate_prompt(survey_question)

        try:
            logging.info(f"Надсилання запиту до '{self.model.model_name}' для судження...")
            response = self.model.generate_content(
                full_prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=self.temperature,
                    response_mime_type="application/json"
                )
            )

            # Перевірка модерації контенту або інших причин пустої відповіді
            if not response.parts:
                safety_ratings = response.prompt_feedback.safety_ratings
                logging.error(f"Відповідь LLM була порожньою або заблокованою. Рейтинги безпеки: {safety_ratings}")
                return None

            return json.loads(response.text)

        except json.JSONDecodeError:
            logging.error(f"Не вдалося декодувати відповідь LLM як JSON. Сирова відповідь: {response.text}")
            return None
        except Exception as e:
            logging.error(f"Відбулася несподівана помилка під час судження LLM: {e}")
            return None


# --- Приклад використання ---
if __name__ == "__main__":
    judge = LLMJudgeForLegalSurvey()

    # --- Хороший приклад ---
    good_legal_survey_question = """
    Наскільки ви згодні або не згодні з тим, що чинні закони про інтелектуальну власність у Швейцарії адекватно захищають AI-генерований контент, припускаючи, що контент відповідає критеріям оригінальності, встановленим Федеральним Верховним Судом?
    (Виберіть один: Повністю не згідний, Не згідний, Нейтрально, Згідний, Повністю згідний)
    """
    print("\n--- Оцінка хорошого питання правового опитування ---")
    judgment_good = judge.judge_survey_question(good_legal_survey_question)
    if judgment_good:
        print(json.dumps(judgment_good, indent=2, ensure_ascii=False))

    # --- Упереджений/поганий приклад ---
    biased_legal_survey_question = """
    Розве ви не згодні, що надмірно обмежувальні закони про захист даних, такі як FADP, перешкоджають необхідним технологічним інноваціям та економічному зростанню у Швейцарії?
    (Виберіть один: Так, Ні)
    """
    print("\n--- Оцінка упередженого питання правового опитування ---")
    judgment_biased = judge.judge_survey_question(biased_legal_survey_question)
    if judgment_biased:
        print(json.dumps(judgment_biased, indent=2, ensure_ascii=False))

    # --- Двозначний/розпливчастий приклад ---
    vague_legal_survey_question = """
    Які ваші думки про правові технології?
    """
    print("\n--- Оцінка розпливчастого питання правового опитування ---")
    judgment_vague = judge.judge_survey_question(vague_legal_survey_question)
    if judgment_vague:
        print(json.dumps(judgment_vague, indent=2, ensure_ascii=False))
```

Python код визначає клас `LLMJudgeForLegalSurvey`, призначений для оцінки якості питань правових опитувань з використанням генеративної AI моделі. Він використовує бібліотеку `google.generativeai` для взаємодії з моделями Gemini.

Основна функціональність включає надсилання питання опитування моделі разом з детальною рубрикою для оцінки. Рубрика визначає п'ять критеріїв для судження питань опитування: Ясність та точність, Нейтральність та упередженість, Релевантність та фокус, Повнота та Відповідність аудиторії. Для кожного критерію присвоюється оцінка від 1 до 5, і потрібне детальне обґрунтування та зворотний зв'язок у виводі. Код конструює промпт, який включає рубрику та питання опитування для оцінки.

Метод `judge_survey_question` надсилає цей промпт сконфігурованій моделі Gemini, запитуючи JSON відповідь, відформатовану відповідно до визначеної структури. Очікуваний вихідний JSON включає загальну оцінку, резюме обґрунтування, детальний зворотний зв'язок по кожному критерію, список проблем та рекомендовану дію. Клас обробляє потенційні помилки під час взаємодії з AI моделлю, такі як проблеми декодування JSON або пусті відповіді. Скрипт демонструє його роботу, оцінюючи приклади питань правових опитувань, ілюструючи, як AI оцінює якість на основі заздалегідь визначених критеріїв.

Перш ніж ми завершимо, давайте розглянемо різні методи оцінки, враховуючи їхні сильні та слабкі сторони.

| Метод оцінки | Сильні сторони | Слабкі сторони |
| --- | --- | --- |
| Людська оцінка | Захоплює тонке поведінку | Важко масштабувати, дорого та затратно за часом через суб'єктивні людські фактори |
| LLM-as-a-Judge | Послідовна, ефективна та масштабована | Проміжні кроки можуть бути пропущені. Обмежена можливостями LLM |
| Автоматизовані метрики | Масштабовані, ефективні та об'єктивні | Потенційне обмеження у захопленні повних можливостей |

# Траєкторії агентів

Оцінка траєкторій агентів має вирішальне значення, оскільки традиційні тести програмного забезпечення недостатні. Стандартний код дає передбачувані результати проходження/невдачі, тоді як агенти працюють імовірнісно, вимагаючи якісної оцінки як кінцевого результату, так і траєкторії агента — послідовності кроків, зроблених для досягнення рішення. Оцінка мультиагентних систем є складним завданням, оскільки вони постійно змінюються. Це вимагає розробки складних метрик, які виходять за межи індивідуальної продуктивності для вимірювання ефективності комунікації та командної роботи. Крім того, самі середовища не є статичними, що вимагає адаптації методів оцінки, включаючи тестові випадки, з часом.

Це включає вивчення якості рішень, процесу міркування та загального результату. Впровадження автоматизованих оцінок цінне, особливо для розробки за межами стадії прототипу. Аналіз траєкторії та використання інструментів включає оцінку кроків, які агент використовує для досягнення мети, таких як вибір інструментів, стратегії та ефективність завдань. Наприклад, агент, що відповідає на запит клієнта про продукт, в ідеалі повинен дотримуватися траєкторії, що включає визначення наміру, використання інструменту пошуку в базі даних, перегляд результатів та генерування звіту. Фактичні дії агента порівнюються з цією очікуваною або ground truth траєкторією для виявлення помилок та неефективності.

Методи порівняння включають точне збігання (що вимагає ідеального збігу з ідеальною послідовністю), упорядковане збігання (правильні дії в порядку, дозволяючи додаткові кроки), збігання в будь-якому порядку (правильні дії в будь-якому порядку, дозволяючи додаткові кроки), точність (вимірюючи релевантність передбачених дій), повноту (вимірюючи скільки основних дій захоплено) та використання одного інструменту (перевіряючи конкретну дію). Вибір метрики залежить від конкретних вимог агента, при цьому високоризикові сценарії потенційно вимагають точного збігання, тоді як більш гнучкі ситуації можуть використовувати упорядковане або невпорядковане збігання.

Оцінка AI агентів включає два основні підходи: використання тестових файлів та використання evalset файлів. Тестові файли у форматі JSON представляють одиничні, прості взаємодії агент-модель або сесії та ідеальні для юніт-тестування під час активної розробки, фокусуючись на швидкому виконанні та простій складності сесій. Кожен тестовий файл містить одну сесію з численними ходами, де хід — це взаємодія користувач-агент, що включає запит користувача, очікувану траєкторію використання інструментів, проміжні відповіді агента та остаточну відповідь.

Наприклад, тестовий файл може деталізувати запит користувача "Вимкнути device_2 у спальні", вказуючи використання агентом інструменту set_device_info з параметрами, такими як location: Bedroom, device_id: device_2 та status: OFF, та очікувану остаточну відповідь "Я встановив статус device_2 як вимкнено". Тестові файли можуть бути організовані в папки та можуть включати файл test_config.json для визначення критеріїв оцінки.

Evalset файли використовують набір даних, який називається "evalset", для оцінки взаємодій, що містять кілька потенційно довгих сесій, придатних для симуляції складних, багатоходових розмов та інтеграційних тестів. Evalset файл складається з численних "evals", кожен представляючий окрему сесію з одним або більше "ходами", які включають користувацькі запити, очікуване використання інструментів, проміжні відповіді та референтну остаточну відповідь.

Приклад evalset може включати сесію, де користувач спочатку запитує "Що ти можеш робити?", а потім каже "Кинь 10-стороннього кубика двічі, а потім перевір, чи є 9 простим числом чи ні", визначаючи очікувані виклики інструменту roll_die та виклик інструменту check_prime разом з остаточною відповіддю, що резюмує кидки кубика та перевірку простого числа.

**Мультиагенти:** Оцінка складної AI системи з численними агентами дуже подібна до оцінки командного проекту. Оскільки існує багато кроків та передач, її складність є перевагою, дозволяючи перевірити якість роботи на кожному етапі. Ви можете вивчити, наскільки добре кожен окремий "агент" виконує свою конкретну роботу, але вам також слід оцінити, як уся система працює в цілому.

Для цього ви ставите ключові питання про динаміку команди, підтримані конкретними прикладами:

- Ефективно ли сотрудничают агенты? Наприклад, після того як "Агент бронювання рейсів" забезпечує рейс, успішно ли він передає правильні дати та пункт призначення "Агенту бронювання готелів"? Невдача у співпраці може привести до бронювання готелю на неправильний тиждень.

- Створили ли вони хороший план та дотримуються його? Уявіть, що план полягає у тому, щоб спочатку забронювати рейс, потім готель. Якщо "Агент готелів" намагається забронювати кімнату до підтвердження рейсу, він відхилився від плану. Ви також перевіряєте, чи не застрягає агент, наприклад, нескінченно шукаючи "ідеальний" орендований автомобіль і ніколи не переходячи до наступного кроку.

- Вибирається ли правильний агент для правильного завдання? Якщо користувач запитує про погоду для своєї подорожі, система повинна використовувати спеціалізованого "Агента погоди", який надає живі дані. Якщо замість цього вона використовує "Агента загальних знань", який дає загальну відповідь типу "влітку зазвичай тепло", вона вибрала неправильний інструмент для роботи.

- Нарешті, покращує ли додавання більшої кількості агентів продуктивність? Якщо ви додаєте нового "Агента бронювання ресторанів" до команди, чи робить це загальне планування подорожі кращим та більш ефективним? Або це створює конфлікти та сповільнює систему, указуючи на проблему масштабованості?

# Від агентів до передових підрядників

Нещодавно була запропонована (Agent Companion, gulli et al.) еволюція від простих AI агентів до передових "підрядників", перехід від імовірнісних, часто ненадійних систем до більш детерміністичних та підзвітних систем, призначених для складних, висока-ризикових середовищ (див. рис. 2).

Сьогоднішні звичайні AI агенти працюють на основі коротких, недостатньо конкретизованих інструкцій, що робить їх придатними для простих демонстрацій, але крихкими у виробництві, де двозначність приводить до невдачі. Модель "підрядника" вирішує це, встановлюючи суворі, формалізовані відносини між користувачем та AI, побудовані на основі чітко визначених та взаємно узгоджених умов, багато в чому як угода про правові послуги в людському світі. Ця трансформація підтримується чотирма ключовими стовпами, які колективно забезпечують ясність, надійність та стійке виконання завдань, які раніше були за межами можливостей автономних систем.

Першим є стовп формалізованого контракту, детальної специфікації, яка служить єдиним джерелом істини для завдання. Це виходить далеко за межи простого промпта. Наприклад, контракт для завдання фінансового аналізу не просто скаже "проаналізувати продажі останнього кварталу"; він потребуватиме "20-сторінкового PDF звіту, що аналізує продажі на європейському ринку з Q1 2025, включаючи п'ять конкретних візуалізацій даних, порівняльний аналіз з Q1 2024 та оцінку ризиків на основі включеного набору даних про порушення ланцюга поставок". Цей контракт явно визначає необхідні результати, їхні точні специфікації, допустимі джерела даних, область роботи та навіть очікувану обчислювальну вартість та час завершення, роблячи результат об'єктивно перевірюваним.

Другим є стовп динамічного життєвого циклу переговорів та зворотного зв'язку. Контракт не є статичною командою, а початком діалогу. Агент-підрядник може проаналізувати первісні умови та вести переговори. Наприклад, якщо контракт вимагає використання конкретного власницького джерела даних, до якого агент не може отримати доступ, він може повернути зворотний зв'язок, заявивши: "Вказана база даних XYZ недоступна. Будь ласка, надайте облікові дані або схваліть використання альтернативної публічної бази даних, що може дещо змінити детализацію даних". Ця фаза переговорів, яка також дозволяє агенту позначати двозначності або потенційні ризики, розв'язує недорозуміння до початку виконання, запобігаючи дорогостоючим невдачам та забезпечуючи ідеальну відповідність кінцевого результату фактичному намірові користувача.

![][image2]

Рис. 2: Приклад виконання контракту між агентами

Третім стовпом є якість-орієнтоване ітеративне виконання. На відміну від агентів, призначених для низьколатентних відповідей, підрядник пріоритизує коректність та якість. Він працює за принципом самовалідації та коригування. Для контракту генерування коду, наприклад, агент не просто напише код; він генеруватиме численні алгоритмічні підходи, компілюватиме та запускатиме їх проти набору юніт-тестів, визначених у контракті, оцінюватиме кожне рішення за метриками, такими як продуктивність, безпека та читаність, та представлятиме лише версію, яка проходить усі критерії валідації. Цей внутрішній цикл генерування, перегляду та вдосконалення власної роботи, поки специфікації контракту не будуть виконані, має вирішальне значення для побудови довіри до його результатів.

Нарешті, четвертим стовпом є ієрархічна декомпозиція через субконтракти. Для завдань значної складності первинний агент-підрядник може діяти як керівник проекту, розбиваючи основну ціль на менші, більш керовані підзадачі. Він досягає цього, генеруючи нові, формальні "субконтракти". Наприклад, головний контракт для "створення мобільного додатку електронної комерції" може бути розкладений первинним агентом на субконтракти для "проектування UI/UX", "розробки модуля аутентифікації користувачів", "створення схеми бази даних продуктів" та "інтеграції платіжного шлюзу". Кожен з цих субконтрактів є повним, незалежним контрактом зі своїми власними результатами та специфікаціями, який може бути призначений іншим спеціалізованим агентам. Ця структурована декомпозиція дозволяє системі вирішувати величезні, багатогранні проекти висок-організованим та масштабованим способом, позначаючи перехід AI від простого інструменту до істинно автономного та надійного рушія розв'язання проблем.

На кінець, ця система підрядників переосмислює взаємодію з AI, вбудовуючи принципи формальної специфікації, переговорів та перевіреного виконання безпосередньо в основну логіку агента. Цей методичний підхід піднімає штучний інтелект від багатообіцяючого, але часто непередбачуваного помічника до надійної системи, здатної автономно керувати складними проектами з аудованою точністю. Вирішуючи критичні проблеми двозначності та надійності, ця модель прокладає шлях для розгортання AI в критично важливих областях, де довіра та підзвітність є першочерговими.

# Google ADK

Перш ніж завершити, давайте розглянемо конкретний приклад фреймворку, який підтримує оцінку. Оцінка агентів за допомогою Google ADK (див. рис. 3) може проводитися трьома методами: веб-інтерфейс (adk web) для інтерактивної оцінки та генерування наборів даних, програмна інтеграція з використанням pytest для включення в тестові трубопроводи та прямий інтерфейс командного рядка (adk eval) для автоматизованих оцінок, придатних для регулярної генерації та верифікації збірок.

![][image3]

Рис. 3: Підтримка оцінки для Google ADK

Веб-інтерфейс дозволяє створювати інтерактивні сесії та зберігати їх в існуючі або нові eval набори, відображаючи статус оцінки. Інтеграція з pytest дозволяє запускати тестові файли як частину інтеграційних тестів, викликаючи AgentEvaluator.evaluate, вказуючи модуль агента та шлях до тестового файлу.

Інтерфейс командного рядка полегшує автоматизовану оцінку, надаючи шлях до модуля агента та файл eval набору, з опціями для вказання файлу конфігурації або виводу детальних результатів. Конкретні evals у рамках більшого eval набору можуть бути обрані для виконання, перечисливши їх після назви файлу eval набору, розділені комами.

# З першого погляду

**Що:** Агентні системи та LLM працюють у складних, динамічних середовищах, де їхня продуктивність може погіршитися з часом. Їхня імовірнісна та недетерміністична природа означає, що традиційне тестування програмного забезпечення недостатнє для забезпечення надійності. Оцінка динамічних мультиагентних систем представляє значний виклик, оскільки їхня постійно змінна природа та природа їхніх середовищ вимагають розробки адаптивних методів тестування та складних метрик, які можуть вимірювати колаборативний успіх поза межами індивідуальної продуктивності. Проблеми, такі як дрейф даних, неочікувані взаємодії, виклики інструментів та відхилення від передбачених цілей, можуть виникнути після розгортання. Тому необхідна безперервна оцінка для вимірювання ефективності агента, продуктивності та дотримання операційних та безпекових вимог.

**Чому:** Стандартизована система оцінки та моніторингу надає систематичний спосіб оцінки та забезпечення безперервної продуктивності інтелектуальних агентів. Це включає визначення чітких метрик для точності, затримки та споживання ресурсів, таких як використання жетонів для LLM. Це також включає передові техніки, такі як аналіз траєкторій агентів для розуміння процесу міркування та використання LLM-as-a-Judge для нюансованих, якісних оцінок. Встановлюючи цикли зворотного зв'язку та системи звітування, ця система дозволяє безперервне вдосконалення, A/B тестування та виявлення аномалій або дрейфу продуктивності, забезпечуючи дотримання агентом його цілей.

**Практичне правило:** Використовуйте цей шаблон при розгортанні агентів у живих, виробничих середовищах, де продуктивність у реальному часі та надійність критичні. Крім того, використовуйте його при необхідності систематичного порівняння різних версій агента або його базових моделей для стимулювання вдосконалень та при роботі в регульованих або висока-ризикових областях, що вимагають відповідності, безпеки та етичних аудитів. Цей шаблон також придатний, коли продуктивність агента може погіршитися з часом через зміни даних або середовища (дрейф), або при оцінці складної поведінки агента, включаючи послідовність дій (траєкторію) та якість суб'єктивних результатів, таких як корисність.

**Візуальне резюме**

![][image4]

Рис. 4: Шаблон проектування оцінки та моніторингу

# Ключові висновки

- Оцінка інтелектуальних агентів виходить за межи традиційних тестів для безперервного вимірювання їхної ефективності, продуктивності та дотримання вимог у реальних середовищах.

- Практичні застосування оцінки агентів включають відслідковування продуктивності у живих системах, A/B тестування для вдосконалень, аудити відповідності та виявлення дрейфу або аномалій у поведінці.

- Базова оцінка агентів включає оцінку точності відповідей, тоді як реальні сценарії вимагають складніших метрик, таких як моніторинг затримки та відслідковування використання жетонів для агентів, що працюють на LLM.

- Траєкторії агентів, послідовність кроків, які агент робить, мають вирішальне значення для оцінки, порівнюючи фактичні дії з ідеальним, ground-truth шляхом для виявлення помилок та неефективності.

- ADK надає структуровані методи оцінки через індивідуальні тестові файли для юніт-тестування та комплексні evalset файли для інтеграційного тестування, обидва визначаючи очікувану поведінку агента.

- Оцінки агентів можуть виконуватися через веб-інтерфейс для інтерактивного тестування, програмно з pytest для інтеграції CI/CD або через інтерфейс командного рядка для автоматизованих робочих процесів.

- Щоб зробити AI надійною для складних, висока-ризикових завдань, ми повинні перейти від простих промптів до формальних "контрактів", які точно визначають перевірювані результати та область. Це структуроване узгодження дозволяє агентам вести переговори, уточнювати двозначності та ітеративно валідувати власну роботу, трансформуючи їх від непередбачуваного інструменту в підзвітну та заслужену довіру систему.

# Висновки

Висновуючи, ефективна оцінка AI агентів вимагає виходу за межи простих перевірок точності до безперервної, багатогранної оцінки їхної продуктивності в динамічних середовищах. Це включає практичний моніторинг метрик, таких як затримка та споживання ресурсів, а також складний аналіз процесу прийняття рішень агента через його траєкторію. Для нюансованих якостей, таких як корисність, інноваційні методи, такі як LLM-as-a-Judge, стають необхідними, тоді як фреймворки, такі як Google ADK, надають структуровані інструменти як для юніт-, так і для інтеграційного тестування. Виклик посилюється мультиагентними системами, де фокус зміщується на оцінку колаборативного успіху та ефективної співпраці.

Для забезпечення надійності у критичних додатках парадигма зміщується від простих, керованих промптами агентів до передових "підрядників", пов'язаних формальними угодами. Ці агенти-підрядники працюють на основі явних, перевірюваних умов, дозволяючи їм вести переговори, декомпозувати завдання та самовалідувати власну роботу для відповідності суворим стандартам якості. Цей структурований підхід трансформує агентів від непередбачуваних інструментів до підзвітних систем, здатних обробляти складні, висока-ризикові завдання. Вкінцевому рахунку, ця еволюція має вирішальне значення для побудови довіри, необхідної для розгортання складного агентного AI у критично важливих областях.

# Посилання

Відповідні дослідження включають:

1. ADK Web: https://github.com/google/adk-web
2. ADK Evaluate: https://google.github.io/adk-docs/evaluate/
3. [Survey on Evaluation of LLM-based Agents](https://arxiv.org/abs/2503.16416)
4. [Agent-as-a-Judge: Evaluate Agents with Agents](https://arxiv.org/abs/2410.10934)
5. Agent Companion, gulli et al: https://www.kaggle.com/whitepaper-agent-companion

[image1]: ../Assets/chapter-19-image1.png
[image2]: ../Assets/chapter-19-image2.jpg
[image3]: ../Assets/chapter-19-image3.png
[image4]: ../Assets/chapter-19-image4.png

---

## Навігація

**Назад:** [Розділ 18. Паттерни безпеки та захисні механізми](Розділ%2018.%20Паттерни%20безпеки.md)<br>
**Вперед:** [Розділ 20. Пріоритизація](Розділ%2020.%20Пріоритизація.md)
