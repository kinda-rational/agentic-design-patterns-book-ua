# Розділ 1: Ланцюги промптів

## Огляд паттерну «Ланцюги промптів»

Ланцюги промптів (також називаються паттерном «конвеєр», Pipeline) — це потужна парадигма для розв'язання складних завдань за допомогою великих мовних моделей (LLM). Замість того щоб чекати від LLM розв'язання складної проблеми за один монолітний крок, метод ланцюгів промптів пропонує стратегію «розділяй і пануй». Суть полягає в декомпозиції вихідного, страшного завдання на послідовність менших і керованих підзадач. Кожна підзадача розв'язується окремим, спеціально розробленим промптом, а результат одного кроку цілеспрямовано передається на вхід наступному кроку в ланцюзі.

Така послідовна обробка вносить у взаємодію з LLM модульність і ясність. Декомпонуючи складну задачу, легше розуміти та налагодити кожен окремий крок, що робить весь процес більш надійним і інтерпретованим. Кожен крок ланцюга можна ретельно сконструювати та оптимізувати під конкретний аспект загальної проблеми, отримуючи точніші та більш зосереджені результати.

Критично важливо, що вихід одного кроку стає входом для наступного. Така передача інформації утворює «ланцюг залежностей», завдяки якому контекст та результати попередніх операцій спрямовують подальшу обробку. Модель спирається на вже виконану роботу, уточнює розуміння та поступово наближається до шуканого рішення.

Крім того, ланцюги промптів — це не лише про розділення задач; вони також дозволяють інтегрувати зовнішні знання та інструменти. На кожному кроці LLM може взаємодіяти із зовнішніми системами, API або базами даних, поповнюючи свої знання та можливості за межами власних навчальних даних. Це радикально розширює потенціал LLM, перетворюючи їх не на ізольовані моделі, а на компоненти ширших інтелектуальних систем.

Значимість ланцюгів промптів виходить за межі «просто розв'язати задачу». Це фундаментальна техніка для побудови складних ШІ-агентів. Такі агенти використовують ланцюги промптів, щоб автономно планувати, міркувати та діяти у динамічних середовищах. При продуманій структурі послідовності промптів агент здатен виконувати задачі, що вимагають багатокрокового міркування, планування та прийняття рішень. Подібні сценарії роботи наближають хід розв'язання до людського, що забезпечує більш природні та ефективні взаємодії зі складними доменами та системами.

**Обмеження одиничних промптів.** Для багатогранних завдань один складний промпт для LLM часто неефективний: модель може «спотикатися» об численні обмеження та інструкції. Це приводить до пропуску інструкцій (instruction neglect), дрейфу контексту (contextual drift), накопичення помилок (error propagation), ситуаціям із недостатком контексту при довгих промптах, а також до галюцинацій — росту ймовірності неправильної інформації через підвищене когнітивне навантаження. Наприклад, запит «проаналізувати звіт маркетингового дослідження, підсумувати висновки, виділити тренди з даними та скласти лист» ризикує провалитися: модель може добре підсумувати, але не витягти коректні дані або погано написати лист.

**Підвищення надійності завдяки послідовній декомпозиції.** Ланцюги промптів усувають ці проблеми шляхом розбиття складної задачі на сфокусований послідовний робочий процес, суттєво підвищуючи керованість та надійність. Для наведеного вище прикладу конвеєр може виглядати так:

1. Вихідний промпт (суммаризація): «Підсумуй ключові висновки наступного звіту маркетингового дослідження: [text]». Вузький фокус підвищує точність першого кроку.
2. Другий промпт (виділення трендів): «Використовуючи суммаризацію, виділи три провідних тренди та витягни конкретні дані, що підтверджують кожен: [output from step 1]». Промпт стає більш обмеженим та спирається на перевірений вихід.
3. Третій промпт (складання листа): «Склади короткий лист для маркетингової команди, описавши виділені тренди та підтвердні дані: [output from step 2]».

Така декомпозиція дає більш тонкий контроль над процесом. Кожен крок простіший та менш двозначний, зменшує когнітивне навантаження на модель та підвищує точність кінцевого результату. Модульність схожа на обчислювальний конвеєр, де кожна функція виконує конкретну операцію та передає результат далі. Щоб забезпечити точність відповіді на кожному кроці, моделі можна задавати роль. У нашому прикладі перший промпт — «Аналітик ринку», другий — «Аналітик торгівлі», третій — «Експерт з документації» і т. д.

**Роль структурованого виходу.** Надійність ланцюга напряму залежить від якості даних, що передаються між кроками. Якщо вихід одного промпта неоднозначний або слабко структурований, наступний крок може «зломатися» на некачісному вході. Тому важливо задавати строгий формат, наприклад JSON або XML.

Приклад структурованого виходу для кроку з трендами:

```json
{
  "trends": [
    {
      "trend_name": "AI-Powered Personalization",
      "supporting_data": "73% of consumers prefer to do business with brands that use personal information to make their shopping experiences more relevant."
    },
    {
      "trend_name": "Sustainable and Ethical Brands",
      "supporting_data": "Sales of products with ESG-related claims grew 28% over the last five years, compared to 20% for products without."
    }
  ]
}
```

Такий формат робить дані машинозчитуваними, що дозволяє однозначно парсити та передавати їх на наступний крок без помилок інтерпретації. Ця практика мінімізує проблеми, пов'язані з інтерпретацією природної мови, та є ключовим компонентом надійних багатокрокових систем на базі LLM.

## Практичні застосування та сценарії використання

Ланцюги промптів — універсальний паттерн для широкого спектра завдань при розробці агентних систем. Його основна користь — розділення складної проблеми на послідовні керовані кроки. Нижче кілька типових сценаріїв:

**1. Контур обробки інформації.** Багато завдань вимагають послідовних трансформацій сирих даних. Наприклад, суммаризація документа, вилучення сутностей, а потім використання цих сутностей для запиту до бази та генерування звіту. Ланцюг промптів може виглядати так:

- Промпт 1: Витягти текст з вказаного URL або документа.
- Промпт 2: Підсумувати очищений текст.
- Промпт 3: Витягти сутності (імена, дати, локації) з суммаризації або вихідного тексту.
- Промпт 4: Використати сутності для пошуку у внутрішній базі знань.
- Промпт 5: Сформувати кінцевий звіт, враховуючи суммаризацію, сутності та результати пошуку.

Це застосовується при автоматичному аналізі контенту, в ШІ-асистентах для досліджень та при генеруванні складних звітів.

**2. Відповіді на складні запитання.** Завдання, що вимагають багатократного міркування або пошуку інформації. Приклад: «Які основні причини краху фондового ринку 1929 року та як уряд реагував?»

- Промпт 1: Виділити підзадачі запитання (причини краху, реакція уряду).
- Промпт 2: Дослідити причини краху 1929 року.
- Промпт 3: Дослідити реакцію уряду на крах 1929 року.
- Промпт 4: Синтезувати інформацію з кроків 2 та 3 в єдину відповідь.

Такий підхід — основа систем багатокрокового висновку та синтезу інформації, коли відповідь не вилучається з однієї точки даних, а вимагає ланцюга логічних кроків та інтеграції різнотипних джерел.

Наприклад, автоматичний дослідник, що генерує комплексний огляд теми, використовує гібридний робочий процес. Спочатку система вилучає багато релевантних статей. Далі паралельно обробляє кожну статтю для вилучення ключової інформації — незалежні підзадачі, що добре підходять для паралелізму. Після завершення вилучення починається послідовний етап: колокація даних, їх синтез у чернетку та фінальний огляд/редагування. Ці кроки залежать один від одного: дані → синтез → редагування. Тут і застосовується ланцюг промптів.

**3. Вилучення та трансформація даних.** Перетворення неструктурованого тексту в структурований формат зазвичай досягається ітеративно, з послідовними поліпшеннями точності та повноти.

- Промпт 1: Спробувати витягти задані поля (наприклад, ім'я, адресу, суму) з рахунка/накладної.
- Обробка: Перевірити повноту та коректність форматів.
- Промпт 2 (умовний): Якщо поля пропущені/некоректні, сформувати промпт на до-вилучення, використовуючи контекст невдалої спроби.
- Обробка: Повторна валідація. При необхідності — повтор.
- Вихід: Валідовані структуровані дані.

Цей підхід особливо актуальний для вилучення та аналізу даних з неструктурованих джерел (форми, рахунки, листи). Наприклад, складні завдання OCR — обробка PDF-форм: етап 1 — вилучення тексту LLM; етап 2 — нормалізація (конвертація «одна тисяча п'ятьдесят» в 1050); етап 3 — делегування точних обчислень зовнішньому калькулятору. LLM формулює задачу, передає нормалізовані числа інструменту та потім включає результат. Такий ланцюг — вилучення тексту → нормалізація → зовнішній інструмент — зазвичай надійніший за один запит до LLM.

**4. Генерування контенту.** Створення складного контенту — процедурна задача, зазвичай розділена на етапи: ідеї, структура, чернетка, ревізія.

- Промпт 1: Генерувати 5 ідей за інтересом користувача.
- Обробка: Користувач вибирає ідею або система підбирає найкращу.
- Промпт 2: Генерувати детальний план за обраною темою.
- Промпт 3: Написати розділ за першим пунктом плану.
- Промпт 4: Написати розділ за другим пунктом, враховуючи попередній; продовжувати за пунктами.
- Промпт 5: Зрецензувати та відредагувати весь текст на зв'язність, тон та граматику.

Це застосовується для NLG-завдань: творчі тексти, техдокументація та інші формати структурованого контенту.

**5. Розмовні агенти зі станом.** Хоча повнофункціональні архітектури стану складніші за просту лінійну сцепку, ланцюги промптів дають базовий механізм підтримання контексту. Кожен хід — новий промпт, що включає інформацію або виділені сутності з попередніх ходів.

- Промпт 1: Обробити висловлення користувача 1, виділити намір та сутності.
- Обробка: Оновити стан діалогу.
- Промпт 2: Враховуючи стан — генерувати відповідь та/або запросити неліквідну інформацію.
- Повтор: Кожен новий хід формує ланцюг, що використовує накопичуваний контекст.

Це фундамент для діалогових агентів, що підтримують зв'язність та когерентність у довгих розмовах.

**6. Генерування та поліпшення коду.** Створення робочого коду — багатокроковий процес, де задача декомпонується на послідовність логічних операцій.

- Промпт 1: Розібратися у запиті до функції; генерувати псевдокод/набросок.
- Промпт 2: Написати первинний код за нарисом.
- Промпт 3: Виявити помилки/зони поліпшення (статичний аналіз або LLM).
- Промпт 4: Переписати/поліпшити код.
- Промпт 5: Додати документацію або тести.

Такий модульний підхід зменшує складність кожного кроку для LLM та дозволяє вставляти детерміновану логіку між викликами моделі: проміжна обробка, валідація, розгалуження. Таким чином, одна «багатоетапна прохання» перетворюється на контрольовану послідовність операцій у межах виконавчого каркасу.

**7. Мультимодальне та багатокрокове міркування.** Аналіз даних різних модальностей вимагає розбиття на дрібні, промпт-орієнтовані завдання. Наприклад, інтерпретація зображення з вбудованим текстом, підписами з виділеними сегментами та таблицею, що пояснює кожен підпис, — типовий випадок.

- Промпт 1: Витягти та розібратися у тексті з зображення користувача.
- Промпт 2: Зіставити витягнутий текст з його підписами/мітками.
- Промпт 3: Інтерпретувати отриману інформацію, використовуючи таблицю, щоб отримати потрібний результат.

## Практичний приклад коду

Реалізація ланцюгів промптів може варіюватися від прямих послідовних викликів у скрипті до використання спеціалізованих фреймворків для управління потоком, станом та інтеграцією компонентів. LangChain, LangGraph, Crew AI та Google Agent Development Kit (ADK) пропонують структуровану середу для побудови та виконання багатокрокових процесів, що особливо зручно для складних архітектур.

Для демонстрації підходять LangChain та LangGraph: їх API орієнтовані на композицію ланцюгів та графів операцій. LangChain надає базові абстракції для лінійних послідовностей, а LangGraph розширює їх до стану та циклів, необхідних для більш «агентних» поведінок. Нижче — приклад базової лінійної послідовності.

Нижче наведений двокроковий ланцюг, що працює як конвеєр обробки тексту. На першому кроці з неструктурованого тексту витягується певна інформація. На другому кроці цей вихід перетворюється на структуровані дані.

Щоб відтворити приклад, встановіть бібліотеки:

```bash
pip install langchain langchain-community langchain-openai langgraph
```

Зважте: `langchain-openai` можна замінити пакетом потрібного постачальника моделі. Далі налаштуйте змінні оточення з API-ключами обраного постачальника (OpenAI, Google Gemini, Anthropic та ін.).

```python
import os from langchain_openai
import ChatOpenAI from langchain_core.prompts
import ChatPromptTemplate from langchain_core.output_parsers
import StrOutputParser

# For better security, load environment variables from a .env file
# from dotenv import load_dotenv
# load_dotenv()
# Make sure your OPENAI_API_KEY is set in the .env file
# Initialize the Language Model (using ChatOpenAI is recommended)
llm = ChatOpenAI(temperature=0)
# --- Prompt 1: Extract Information ---
prompt_extract = ChatPromptTemplate.from_template(
  "Extract the technical specifications from the following text:\n\n{text_input}"
)

# --- Prompt 2: Transform to JSON ---

prompt_transform = ChatPromptTemplate.from_template(
  "Transform the following specifications into a JSON object with 'cpu', 'memory', and 'storage' as keys:\n\n{specifications}"
)

# --- Build the Chain using LCEL ---
# The StrOutputParser() converts the LLM's message output to a simple string.

extraction_chain = prompt_extract | llm | StrOutputParser()
# The full chain passes the output of the extraction chain into the 'specifications'
# variable for the transformation prompt.

full_chain = (
  {"specifications": extraction_chain}
    | prompt_transform
    | llm
    | StrOutputParser()
  )
  # --- Run the Chain --- input_text = "The new laptop model features a 3.5 GHz octa-core processor, 16GB of RAM, and a 1TB NVMe SSD."
  # Execute the chain with the input text dictionary.

  final_result = full_chain.invoke({"text_input": input_text}) print("\n--- Final JSON Output ---") print(final_result)
```

Цей Python-код показує, як використовувати LangChain для обробки тексту. Тут застосовані два промпти: перший витягує технічні характеристики з рядка, другий — форматує їх у JSON-об'єкт. Взаємодія з моделлю виконує `ChatOpenAI`, а `StrOutputParser` приводить відповідь до рядка. LCEL (LangChain Expression Language) полегшує композицію промптів та моделі. Ланцюг `extraction_chain` витягує характеристики; потім `full_chain` передає їх у промпт трансформації. На вхід подається опис ноутбука, на виході — JSON-рядок зі структурованими характеристиками.

# Інженерія контексту та інженерія промптів

Інженерія контексту (див. рис. 1) — це систематична дисципліна проектування, побудови та доставки повної інформаційної середи моделі до початку генерації токенів. Цей підхід стверджує, що якість відповідей залежить не стільки від архітектури моделі, скільки від багатства наданого контексту.

![][image2]

Рис. 1. Інженерія контексту — дисципліна побудови багатої, цілісної інформаційної середи для ШІ; якість цієї середи — ключовий фактор передової агентної продуктивності.

Це — розвиток класичної «інженерії промптів», сфокусованої на формулюванні конкретного запиту. Інженерія контексту розширює рамки: включає системний промпт (базові інструкції: наприклад, «ви — технічний письменник; тон — офіційний та точний»), зовнішні дані (витягнені документи, результати інструментів/інтеграцій), а також неявні дані (особистість користувача, історія взаємодій, стан навколишнього середовища). Принцип: навіть передові моделі дають посередні результати при вузькому та погано сконструйованому поданні середи.

Задача переосмислюється: не просто відповісти, а сформувати операційну картину для агента. Наприклад, агент спочатку інтегрує доступність з календаря (вихід інструменту), характер відносин з адресатом листа (неявні дані) та нотатки попередніх зустрічей (retrieval), а потім формує релевантну, персоналізовану, практично корисну відповідь. «Інженерія» означає побудову надійних конвеєрів завантаження та трансформації даних у рантаймі та створення контурів зворотного зв'язку для поліпшення якості контексту.

Для впровадження застосовуються системи авто-налаштування в масштабі. Наприклад, Google Vertex AI Prompt Optimizer може поліпшувати якість, автоматично оцінюючи відповіді на тестових наборах та метриках. Підхід ефективний для адаптації промптів та системних інструкцій під різні моделі без ручної переробки: оптимізатору передають приклади, системні інструкції та шаблон; він ітеративно поліпшує контекст.

Це і відрізняє «простий інструмент» від «контекстно-осведомленої системи»: контекст стає першокласною сутністю — що знає агент, коли знає та як використовує. В результаті модель краще розуміє наміри, історію та середу користувача. Інженерія контексту — ключовий метод переходу від статичних чат-ботів до здатних, ситуаційно-осведомлених систем.

## Коротко

**Що:** Складні завдання часто перегружають LLM, якщо розв'язуються одним промптом. Зростає когнітивне навантаження, підвищується ризик пропуску інструкцій, втрати контексту та генерування неправильної інформації. Один монолітний промпт погано справляється з численними обмеженнями та послідовним міркуванням — результат ненадійний та неточний.

**Чому:** Ланцюги промптів стандартизують рішення — розділяють складну проблему на послідовність менших, взаємопов'язаних підзадач. Кожен крок — сфокусований промпт, який підвищує надійність та керованість. Вихід одного кроку — вхід наступного, формуючи логічний робочий процес, що поступово приводить до кінцевого рішення. Модульність спрощує налагодження та дозволяє інтегрувати зовнішні інструменти та структуровані формати між кроками. Цей паттерн — основа для складних ШІ-агентів, здатних планувати, міркувати та виконувати багатокрокові процеси.

**Практичне правило:** Застосовуйте, коли задача занадто складна для одного промпта, включає кілька рознотипних стадій, вимагає інтеграції з зовнішніми інструментами між кроками або коли ви будуєте агентні системи з багатокроковим міркуванням та станом.

**Візуальне резюме**

![][image1]

Рис. 2. Паттерн «Ланцюги промптів»: агенти отримують серію промптів від користувача, а вихід кожного кроку служить входом для наступного в ланцюзі.

## Ключові висновки

Нижче — основні тези:

- Ланцюги промптів розділяють складні завдання на послідовність менших, сфокусованих кроків (іноді — «конвеєр»).
- Кожен крок — виклик LLM або логіка обробки, що використовує вихід попереднього кроку як вхід.
- Паттерн підвищує надійність та керованість складних взаємодій з LLM.
- Фреймворки LangChain/LangGraph та Google ADK надають зручні засоби для визначення, управління та виконання таких багатокрокових послідовностей.

## Висновок

Декомпонуючи складні проблеми на ланцюг більш простих підзадач, ланцюги промптів дають надійний каркас для управління LLM. Підхід «розділяй і пануй» суттєво підвищує якість та контрольованість результату, фокусуючи модель на одній конкретній дії за раз. Як фундаментальний паттерн, він дозволяє будувати складних ШІ-агентів з багатокроковим міркуванням, інтеграцією інструментів та управлінням станом. Оволодіння ланцюгами промптів — ключ до створення надійних контекстно-осведомлених систем, здатних виконувати складні робочі процеси далеко за межами можливостей одного промпта.

## Посилання

1. [Документація LangChain по LCEL](https://python.langchain.com/v0.2/docs/core_modules/expression_language/)
2. [Документація LangGraph](https://langchain-ai.github.io/langgraph/)
3. [Prompt Engineering Guide — Chaining Prompts](https://www.promptingguide.ai/techniques/chaining)
4. [OpenAI API — General Prompting Concepts](https://platform.openai.com/docs/guides/gpt/prompting)
5. [Документація Crew AI (Tasks and Processes)](https://docs.crewai.com/)
6. [Google AI for Developers (Prompting Guides)](https://cloud.google.com/discover/what-is-prompt-engineering?hl=en)
7. [Vertex Prompt Optimizer](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer)

[image1]: ../Assets/chapter-1-image1.png
[image2]: ../Assets/chapter-1-image2.png

---

## Навігація

**Назад:** [Що робить AI систему агентом?](../2.%20Що%20робить%20AI%20систему%20агентом.md)<br>
**Вперед:** [Розділ 2. Маршрутизація](Розділ%202.%20Маршрутизація.md)
