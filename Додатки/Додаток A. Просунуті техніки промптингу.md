# Додаток A: Просунуті техніки промптингу

## Вступ до промптингу

Промптинг, основний інтерфейс для взаємодії з мовними моделями, являє собою процес створення вхідних даних для спрямування моделі до генерування бажаного вихідного результату. Це включає структурування запитів, надання релевантного контексту, вказування формату виводу та демонстрацію очікуваних типів відповідей. Добре спроектовані промпти можуть максимізувати потенціал мовних моделей, призводячи до точних, релевантних та творчих відповідей. На противагу цьому, погано спроектовані промпти можуть призвести до неоднозначних, нерелевантних або помилкових результатів.

Мета промптинг-інженерії полягає в послідовному отриманні високоякісних відповідей від мовних моделей. Це вимагає розуміння можливостей та обмежень моделей та ефективного донесення передбачених цілей. Це включає розвиток експертизи в спілкуванні зі ШІ шляхом вивчення того, як найкраще його інструктувати.

Цей додаток детально розглядає різні техніки промптингу, які виходять за межи базових методів взаємодії. Він досліджує методології для структурування складних запитів, покращення здатності моделі до міркування, контролю форматів виводу та інтеграції зовнішної інформації. Ці техніки застосовуються для створення широкого спектру застосувань, від простих чат-ботів до складних мультиагентних систем, та можуть покращити продуктивність та надійність агентних застосувань.

Агентні патерни, архітектурні структури для створення інтелектуальних систем, детально описані у основних розділах. Ці патерни визначають, як агенти планують, використовують інструменти, керують пам'яттю та співробітничають. Ефективність цих агентних систем залежить від їхньої здатності змістовно взаємодіяти з мовними моделями.

## Основні принципи промптингу

Основні принципи ефективного промптингу мовних моделей:

Ефективний промптинг базується на фундаментальних принципах, що спрямовують спілкування з мовними моделями, застосовні до різних моделей та складності завдань. Оволодіння цими принципами необхідне для послідовної генерації корисних та точних відповідей.

**Ясність та специфічність**: Інструкції повинні бути однозначними та точними. Мовні моделі інтерпретують патерни; множинні інтерпретації можуть призвести до небажаних відповідей. Визначте завдання, бажаний формат виводу та будь-які обмеження або вимоги. Уникайте розпливчастих формулювань або припущень. Неадекватні промпти дають неоднозначні та неточні відповіді, перешкоджаючи змістовному виводу.

**Стислість**: Хоча специфічність критично важлива, вона не повинна компрометувати стислість. Інструкції повинні бути прямими. Непотрібні формулювання або складні структури речень можуть заплутати модель або затьмарити основну інструкцію. Промпти повинні бути простими; те, що плутає користувача, ймовірно, плутає й модель. Уникайте вишуканих виразів та надлишкової інформації. Використовуйте прямі фрази та активні дієслова для чіткого позначення бажаної дії. Ефективні дієслова включають: Діяй, Аналізуй, Категоризуй, Класифікуй, Порівнюй, Супоставляй, Створюй, Описуй, Визначай, Оцінюй, Виділяй, Знаходь, Генеруй, Ідентифікуй, Перераховуй, Вимірюй, Організовуй, Розбирай, Вибирай, Передбачай, Надавай, Ранжуй, Рекомендуй, Повертай, Отримуй, Переписуй, Виділяй, Показуй, Сортуй, Підсумовуй, Перекладай, Пиши.

**Використання дієслів**: Вибір дієслова є ключовим інструментом промптингу. Дієслова дії вказують на очікувану операцію. Замість "Подумай про підсумовування цього" більш ефективною є пряма інструкція типу "Підсумуй наступний текст". Точні дієслова спрямовують модель на активацію релевантних навчальних даних та процесів для цього конкретного завдання.

**Інструкції замість обмежень**: Позитивні інструкції зазвичай більш ефективні, ніж негативні обмеження. Вказання бажаної дії є кращим, ніж опис того, чого не слід робити. Хоча обмеження мають місце для безпеки або строгого форматування, надмірна залежність від них може змусити модель сконцентруватися на уникненні замість мети. Формулюйте промпти для прямого спрямування моделі. Позитивні інструкції відповідають людським перевагам керівництва та зменшують плутанину.

**Експериментування та ітерація**: Промптинг-інженерія — це ітеративний процес. Визначення найбільш ефективного промпта вимагає множинних спроб. Почніть з чорнетки, протестуйте її, проаналізуйте вивід, виявіть недоліки та вдосконаліть промпт. Варіації моделей, конфігурації (такі як температура або top-p) та незначні зміни формулювань можуть дати різні результати. Документування спроб критично важливе для навчання та вдосконалення. Експериментування та ітерація необхідні для досягнення бажаної продуктивності.

Ці принципи формують основу ефективного спілкування з мовними моделями. Пріоритизуючи ясність, стислість, дієслова дії, позитивні інструкції та ітерацію, встановлюється надійна основа для застосування більш просунутих технік промптингу.

## Базові техніки промптингу

Спираючись на ключові принципи, фундаментальні техніки надають мовним моделям різні рівні інформації або приклади для спрямування їхніх відповідей. Ці методи служать початковою фазою в промптинг-інженерії та ефективні для широкого спектру застосувань.

### Zero-Shot промптинг

Zero-shot промптинг є найбільш базовою формою промптингу, де мовна модель отримує інструкцію та вхідні дані без будь-яких прикладів бажаної пари вхід-вихід. Вона повністю покладається на попередньо навчені дані моделі для розуміння завдання та генерування релевантної відповіді. По суті, zero-shot промпт складається з опису завдання та вхідного тексту для запуску процесу.

- **Коли використовувати**: Zero-shot промптинг часто достатній для завдань, які модель, ймовірно, часто зустрічала під час навчання, таких як прості питання-відповіді, завершення тексту або базове підсумовування простого тексту. Це найшвидший підхід для першої спроби.
- **Приклад**:
  Переведи наступне англійське речення на французьку: 'Hello, how are you?'

### One-Shot промптинг

One-shot промптинг включає надання мовній моделі одного прикладу вхідних даних та відповідної бажаної вихідної результату перед поданням фактичного завдання. Цей метод служить як початкова демонстрація для ілюстрації патерну, який модель повинна відтворити. Мета полягає у забезпеченні моделі конкретним екземпляром, який вона може використовувати як шаблон для ефективного виконання даного завдання.

- **Коли використовувати**: One-shot промптинг корисний, коли бажаний формат виводу або стиль є специфічним або менш поширеним. Він дає моделі конкретний екземпляр для навчання. Може покращити продуктивність порівняно з zero-shot для завдань, які вимагають певної структури або тону.
- **Приклад**:
  Переведи наступні англійські речення на іспанську:
  English: 'Thank you.'
  Spanish: 'Gracias.'

  English: 'Please.'
  Spanish:

### Few-Shot промптинг

Few-shot промптинг покращує one-shot промптинг, надаючи кілька прикладів, зазвичай від трьох до п'яти, пар вхід-вихід. Це спрямоване на демонстрацію більш чіткого патерну очікуваних відповідей, підвищуючи ймовірність того, що модель відтворить цей патерн для нових вхідних даних. Цей метод надає множинні приклади для спрямування моделі дотримуватися певного патерну виводу.

- **Коли використовувати**: Few-shot промптинг особливо ефективний для завдань, де бажаний вивід вимагає дотримання певного формату, стилю або демонстрації нюансованих варіацій. Він чудово підходить для завдань класифікації, видобування даних з певними схемами або генерування тексту в певному стилі, особливо коли zero-shot або one-shot не дають послідовних результатів. Використання щонайменше трьох-п'яти прикладів є загальним правилом, коригованим залежно від складності завдання та обмежень токенів моделі.
- **Важливість якості та різноманітності прикладів**: Ефективність few-shot промптингу значною мірою залежить від якості та різноманітності наданих прикладів. Приклади повинні бути точними, репрезентативними для завдання та охоплювати потенційні варіації або граничні випадки, з якими модель може зіткнутися. Високоякісні, добре написані приклади критично важливі; навіть невелика помилка може заплутати модель і призвести до небажаного виводу. Включення різноманітних прикладів допомагає моделі краще узагальнюватись на невидимі вхідні дані.
- **Змішування класів у прикладах класифікації**: При використанні few-shot промптингу для завдань класифікації (де модель повинна категоризувати вхідні дані в попередньо визначені класи), найкращою практикою є змішування порядку прикладів з різних класів. Це запобігає потенційному переоснащенню моделі на певну послідовність прикладів та забезпечує вивчення ключових характеристик кожного класу незалежно, що призводить до більш надійної та узагальнюваної продуктивності на невидимих даних.
- **Еволюція до "Many-Shot" навчання**: Оскільки сучасні LLM, такі як Gemini, стають сильнішими в моделюванні довгого контексту, вони стають високоефективними у використанні "many-shot" навчання. Це означає, що оптимальна продуктивність для складних завдань тепер може бути досягнута включенням значно більшої кількості прикладів — іноді навіть сотень — безпосередньо в промпт, дозволяючи моделі вивчати більш складні патерни.
- **Приклад**:
  Класифікуй настрій наступних рецензій на фільми як ПОЗИТИВНА, НЕЙТРАЛЬНА або НЕГАТИВНА:

  Рецензія: "Гра акторів була чудовою, а сюжет захоплюючим."
  Настрій: ПОЗИТИВНА

  Рецензія: "Було нормально, нічого особливого."
  Настрій: НЕЙТРАЛЬНА

  Рецензія: "Я вважав сюжет заплутаним, а персонажів неприємними."
  Настрій: НЕГАТИВНА

  Рецензія: "Візуальні ефекти були вражаючими, але діалоги були слабкими."
  Настрій:

Розуміння того, коли застосовувати zero-shot, one-shot та few-shot техніки промптингу, а також обдумане створення та організація прикладів, необхідні для підвищення ефективності агентних систем. Ці базові методи служать основою для різних стратегій промптингу.

## Структурування промптів

Крім базових технік надання прикладів, спосіб структурування промпта відіграє критичну роль у спрямуванні мовної моделі. Структурування включає використання різних секцій або елементів у промпті для надання окремих типів інформації, таких як інструкції, контекст або приклади, у ясній та організованій манері. Це допомагає моделі правильно розпарсити промпт та зрозуміти конкретну роль кожної частини тексту.

### Системний промптинг

Системний промптинг встановлює загальний контекст та мету для мовної моделі, визначаючи її передбачену поведінку для взаємодії чи сеансу. Це включає надання інструкцій або фонової інформації, які встановлюють правила, персону або загальну поведінку. На відміну від конкретних запитів користувачів, системний промпт надає фундаментальні керівні принципи для відповідей моделі. Він впливає на тон, стиль та загальний підхід моделі протягом всієї взаємодії. Наприклад, системний промпт може інструктувати модель послідовно відповідати стисло та корисно або забезпечувати, щоб відповіді відповідали загальній аудиторії. Системні промпти також використовуються для контролю безпеки та токсичності шляхом включення керівних принципів, таких як утримання поважного мовлення.

Крім того, для максимізації їхної ефективності системні промпти можуть проходити автоматичну оптимізацію через ітеративне вдосконалення на основі LLM. Сервіси, такі як Vertex AI Prompt Optimizer, полегшують це шляхом систематичного покращення промптів на основі користувацьких метрик та цільових даних, забезпечуючи максимально можливу продуктивність для даного завдання.

- **Приклад**:
  Ти корисний та безпечний ШІ-помічник. Відповідай на всі запити ввічливо та інформативно. Не генеруй контент, який є шкідливим, упередженим або неналежним.

### Ролевий промптинг

Ролевий промптинг призначає конкретного персонажа, персону або ідентичність мовній моделі, часто у поєднанні з системним або контекстуальним промптингом. Це включає інструктування моделі прийняти знання, тон та стиль спілкування, пов'язані з цією роллю. Наприклад, промпти типу "Діяй як туристичний гід" або "Ти експерт з аналізу даних" спрямовують модель відображати перспективу та експертизу призначеної ролі. Визначення ролі надає рамки для тону, стилю та сфокусованої експертизи, спрямовані на покращення якості та релевантності виводу. Бажаний стиль у межах ролі також може бути вказаний, наприклад, "гумористичний та натхненний стиль".

- **Приклад**:
  Діяй як досвідчений туристичний блогер. Напиши короткий, захопливий абзац про найкращу приховану жемчужину в Римі.

### Використання роздільників

Ефективний промптинг включає чіткість розрізнення інструкцій, контексту, прикладів та вхідних даних для мовних моделей. Роздільники, такі як потрійні зворотні скісні наклади (\`\`\`), XML-теги (<instruction>, <context>) або маркери (---), можуть використовуватися для візуального та програмного розділення цих секцій. Ця практика, широко використовувана в промптинг-інженерії, мінімізує неправильну інтерпретацію моделлю, забезпечуючи ясність щодо ролі кожної частини промпта.

- **Приклад**:
  <instruction>Підсумуй наступну статтю, сконцентруючись на основних аргументах, представлених автором.</instruction>
  <article>
  [Вставте повний текст статті тут]
  </article>

## Контекстна інженерія

Контекстна інженерія, на відміну від статичних системних промптів, динамічно надає фонову інформацію, критично важливу для завдань та розмов. Ця постійно змінювана інформація допомагає моделям розуміти нюанси, пам'ятати минулі взаємодії та інтегрувати релевантні деталі, що призводить до обґрунтованих відповідей та більш плавних обмінів. Приклади включають попередній діалог, релевантні документи (як у Retrieval Augmented Generation) або специфічні операційні параметри. Наприклад, при обговоренні подорожі до Японії можна попросити три сімейні активності в Токіо, використовуючи існуючий контекст розмови. В агентних системах контекстна інженерія є фундаментальною для основних поведінок агента, таких як збереження пам'яті, прийняття рішень та координація між підзавданнями. Агенти з динамічними контекстними конвеєрами можуть підтримувати цілі протягом часу, адаптувати стратегії та безперешкодно співробітничати з іншими агентами чи інструментами — якості, необхідні для довгострокової автономії. Ця методологія стверджує, що якість виводу моделі залежить більше від багатства наданого контексту, ніж від архітектури моделі. Вона означає значну еволюцію від традиційної промптинг-інженерії, яка спочатку сконцентрувалася на оптимізації формулювання безпосередніх запитів користувачів. Контекстна інженерія розширює її область, включаючи множинні шари інформації.

Ці шари включають:

1. **Системні промпти**: Фундаментальні інструкції, які визначають операційні параметри ШІ (наприклад, "Ти технічний письменник; твій тон повинен бути формальним та точним").
2. **Зовнішні дані**:
   - **Отримані документи**: Інформація, активно видобута з бази знань для інформування відповідей (наприклад, отримання технічних специфікацій).
   - **Виходи інструментів**: Результати від ШІ, що використовує зовнішний API для даних у реальному часі (наприклад, запит календаря щодо наявності).
3. **Неявні дані**: Критична інформація, така як ідентичність користувача, історія взаємодій та стан оточення. Включення неявного контексту являє собою виклики, пов'язані з приватністю та етичним керуванням даними. Тому надійне керування необхідне для контекстної інженерії, особливо в секторах, таких як підприємства, охорона здоров'я та фінанси.

Основний принцип полягає в тому, що навіть просунуті моделі показують низку продуктивності з обмеженим або погано сконструйованим представленням їхнього операційного середовища. Ця практика перекреслює завдання від простого відповідання на питання до будування всеосяжної операційної картини для агента. Наприклад, агент з контекстною інженерією інтегрував би доступність календаря користувача (вивід інструмента), професійні стосунки з отримувачем електронної пошти (неявні дані) та примітки з попередніх зустрічей (отримані документи) перед відповіддю на запит. Це дозволяє моделі генерувати висок релевантні, персоналізовані та прагматично корисні виходи. Аспект "інженерії" включає створення надійних конвеєрів для отримання та трансформації цих даних під час виконання та встановлення циклів зворотного зв'язку для постійного покращення якості контексту.

Для реалізації цього спеціалізовані системи налаштування, такі як оптимізатор промптів Vertex AI від Google, можуть автоматизувати процес покращення у масштабі. Систематично оцінюючи відповіді на основі зразків вхідних даних та попередньо визначених метрик, ці інструменти можуть покращити продуктивність моделі та адаптувати промпти та системні інструкції для різних моделей без обширного ручного переписування. Надання оптимізатору зразків промптів, системних інструкцій та шаблону дозволяє йому програмно вдосконалювати контекстуальні входи, пропонуючи структурований метод для реалізації необхідних циклів зворотного зв'язку для складної контекстної інженерії.

Цей структурований підхід відрізняє рудиментарний ШІ-інструмент від більш складної, контекстно-обізнаної системи. Він розглядає контекст як основний компонент, підкреслюючи те, що агент знає, коли він це знає та як він використовує цю інформацію. Ця практика гарантує, що модель має всеосяжне розуміння намірів користувача, історії та поточного середовища. Зрештою, контекстна інженерія є критично важливою методологією для трансформації без стану чат-ботів у високоспроможні, ситуаційно-обізнані системи.

## Структурований вивід

Часто мета промптингу полягає не лише в отриманні вільного текстового ответу, але у видобуванні або генеруванні інформації у певному, машино-читаному форматі. Запит структурованого виводу, такого як JSON, XML, CSV або Markdown-таблиці, є критично важливою технікою структурування. Явно запитуючи вивід у певному форматі та потенційно надаючи схему або приклад бажаної структури, ви спрямовуєте модель організувати свою відповідь способом, який можна легко розпарсити та використовувати іншими частинами вашої агентної системи або застосування. Повернення JSON-об'єктів для видобування даних корисно, оскільки змушує модель створювати структуру та може обмежити галюцинації. Рекомендується експериментувати з форматами виводу, особливо для некреативних завдань, таких як видобування або категоризація даних.

- **Приклад**:
  Виділи наступну інформацію з тексту нижче та поверни її як JSON-об'єкт з ключами "name", "address" та "phone_number".

  Текст: "Зв'яжіться з Іваном Смирновим за адресою вул. Головна, 123, Будь-яке місто, або дзвоніть за номером (555) 123-4567."

Ефективне використання системних промптів, призначення ролей, контекстуальної інформації, роздільників та структурованого виводу значно покращує ясність, контроль та корисність взаємодій з мовними моделями, забезпечуючи міцну основу для розробки надійних агентних систем. Запит структурованого виводу критично важливий для створення конвеєрів, де вивід мовної моделі служить входом для наступних системних або обробних кроків.

### Використання Pydantic для об'єктно-орієнтованого фасаду

Потужна техніка для принуження структурованого виводу та покращення взаємосумісності полягає у використанні генерованих LLM даних для заповнення екземплярів об'єктів Pydantic. Pydantic — це Python-бібліотека для валідації даних та керування настройками, що використовує анотації типів Python. Визначаючи модель Pydantic, ви створюєте чітку та принудову схему для бажаної структури даних. Цей підхід ефективно надає об'єктно-орієнтований фасад виводу промпта, трансформуючи сирий текст або напіввідкритоструковані дані в валідовані, типізовані Python-об'єкти.

Ви можете безпосередньо розпарсити JSON-рядок від LLM в об'єкт Pydantic, використовуючи метод model_validate_json. Це особливо корисно, оскільки поєднує парсинг та валідацію в одному кроці.

```python
from pydantic import BaseModel, EmailStr, Field, ValidationError
from typing import List, Optional
from datetime import date

# --- Визначення моделі Pydantic ---
class User(BaseModel):
    name: str = Field(..., description="Повне ім'я користувача.")
    email: EmailStr = Field(..., description="Email-адреса користувача.")
    date_of_birth: Optional[date] = Field(None, description="Дата народження користувача.")
    interests: List[str] = Field(default_factory=list, description="Список інтересів користувача.")

# --- Гіпотетичний вивід LLM ---
llm_output_json = """
{
    "name": "Аліса Іванова",
    "email": "alice.i@example.com",
    "date_of_birth": "1995-07-21",
    "interests": [
        "Обробка природної мови",
        "Програмування на Python",
        "Садівництво"
    ]
}
"""

# --- Парсинг та валідація ---
try:
    # Використовуємо метод класу model_validate_json для парсингу JSON-рядка.
    # Цей єдиний крок парсить JSON та валідує дані відповідно до моделі User.
    user_object = User.model_validate_json(llm_output_json)

    # Тепер ви можете працювати з чистим, типо-безпечним Python-об'єктом.
    print("Успішно створений об'єкт User!")
    print(f"Ім'я: {user_object.name}")
    print(f"Email: {user_object.email}")
    print(f"Дата народження: {user_object.date_of_birth}")
    print(f"Перший інтерес: {user_object.interests[0]}")

    # Ви можете отримувати доступ до даних як до будь-якого іншого атрибута Python-об'єкта.
    # Pydantic уже трансформував рядок 'date_of_birth' в об'єкт datetime.date.
    print(f"Тип date_of_birth: {type(user_object.date_of_birth)}")

except ValidationError as e:
    # Якщо JSON неправильно сформований або дані не відповідають типам моделі,
    # Pydantic видасть ValidationError.
    print("Не вдалось валідувати JSON від LLM.")
    print(e)
```

Цей Python-код демонструє, як використовувати бібліотеку Pydantic для визначення моделі даних та валідації JSON-даних. Він визначає модель User з полями для імені, email, дати народження та інтересів, включаючи підказки типів та описи. Код потім парсить гіпотетичний JSON-вивід від Large Language Model (LLM), використовуючи метод model_validate_json моделі User. Цей метод обробляє як JSON-парсинг, так і валідацію даних відповідно до структури та типів моделі. Нарешті, код отримує доступ до валідованих даних з результуючого Python-об'єкта та включає обробку помилок для ValidationError у випадку невалідного JSON.

Для XML-даних бібліотека xmltodict може використовуватися для конвертації XML в словник, який потім може бути переданий моделі Pydantic для парсингу. Використовуючи псевдоніми Field у вашій моделі Pydantic, ви можете безперешкодно зіставити часто багатослівну або багату атрибутами структуру XML з полями вашого об'єкта.

Ця методологія є бездоганною для забезпечення взаємосумісності LLM-компонентів з іншими частинами більшої системи. Коли вивід LLM інкапсульований в об'єкт Pydantic, він може бути надійно переданий іншим функціям, API або конвеєрам обробки даних з впевненістю, що дані відповідають очікуваній структурі та типам. Ця практика "парсити, не валідувати" на межах компонентів вашої системи призводить до більш надійних та утримуваних застосувань.

## Техніки міркування та процесів мислення

Великі мовні моделі перевершують розпізнавання патернів та генерування тексту, але часто зіткаються з викликами в завданнях, що вимагають складного, багатоступеневого міркування. Цей додаток зосереджується на техніках, розроблених для покращення цих здатностей до міркування шляхом спонукання моделей розкривати свої внутрішні процеси мислення. Зокрема, він розглядає методи для покращення логічної дедукції, математичних обчислень та планування.

### Chain of Thought (CoT)

Техніка Chain of Thought (CoT) промптингу є потужним методом для покращення здатностей мовних моделей до міркування шляхом явного спонукання моделі генерувати проміжні кроки міркування перед отриманням остаточної відповіді. Замість простого запиту результату ви інструктуєте модель "думати крок за кроком". Цей процес відображає те, як людина може розбити проблему на менші, керовані частини та проробити їх послідовно.

CoT допомагає LLM генерувати більш точні відповіді, особливо для завдань, що вимагають певної форми обчислення або логічної дедукції, де моделі інакше могли б мати проблеми та виробляти неправильні результати. Генеруючи ці проміжні кроки, модель із більшою ймовірністю залишається на правильному шляху та виконує необхідні операції правильно.

Існують два основні варіанти CoT:

- **Zero-Shot CoT**: Це включає просте додавання фрази "Давайте думати крок за кроком" (або подібного формулювання) до вашого промпта без надання будь-яких прикладів процесу міркування. Дивовижно, що для багатьох завдань це просте додавання може значно покращити продуктивність моделі, запускаючи її здатність розкривати внутрішній слід міркування.

  - **Приклад (Zero-Shot CoT)**:
    Якщо поїзд рухається зі швидкістю 60 миль на годину й долає відстань 240 миль, скільки часу тривала поїздка? Давайте думати крок за кроком.

- **Few-Shot CoT**: Це поєднує CoT з few-shot промптингом. Ви надаєте моделі кілька прикладів, де показано вхідні дані, покроковий процес міркування та остаточний вивід. Це дає моделі більш ясний шаблон для виконання міркування та структурування відповіді, часто призводячи до навіть кращих результатів на більш складних завданнях порівняно з zero-shot CoT.

  - **Приклад (Few-Shot CoT)**:
    П: Сума трьох послідовних цілих чисел дорівнює 36. Які це числа?
    В: Нехай перше ціле число буде x. Наступне послідовне ціле число — x+1, а третє — x+2. Сума дорівнює x + (x+1) + (x+2) = 3x + 3. Ми знаємо, що сума дорівнює 36, тому 3x + 3 = 36. Віднімаємо 3 з обох сторін: 3x = 33. Ділимо на 3: x = 11. Числа: 11, 11+1=12 та 11+2=13. Числа: 11, 12 та 13.

    П: У Сари є 5 яблук, і вона купує ще 8. Вона їсть 3 яблука. Скільки яблук у неї залишилось? Давайте думати крок за кроком.
    В: Давайте думати крок за кроком. Сара починає з 5 яблук. Вона купує ще 8, тому додає 8 до своєї початкової кількості: 5 + 8 = 13 яблук. Потім вона їсть 3 яблука, тому віднімаємо 3 від загальної кількості: 13 - 3 = 10. У Сари залишилось 10 яблук. Відповідь: 10.

CoT пропонує кілька переваг. Його відносно легко реалізувати, і він може бути високоефективним з готовими LLM без необхідності тонкого налаштування. Значна перевага — підвищена інтерпретованість виводу моделі; ви можете бачити кроки міркування, які вона виконала, що допомагає зрозуміти, чому вона прийшла до певної відповіді та налаштовувати, якщо щось пішло не так. Крім того, CoT підвищує надійність промптів для різних версій мовних моделей, що означає, що продуктивність з меншою ймовірністю погіршиться при оновленні моделі. Основний недолік полягає в тому, що генерування кроків міркування збільшує довжину виводу, призводячи до вищого використання токенів, що може збільшити витрати та час відповіді.

Найкращі практики для CoT включають забезпечення представлення остаточної відповіді після кроків міркування, оскільки генерування міркування впливає на наступні передбачення токенів для відповіді. Також для завдань з єдиною правильною відповіддю (наприклад, математичні задачі) рекомендується встановити температуру моделі на 0 (жадне декодування) при використанні CoT для забезпечення детермінованого вибору найбільш імовірного наступного токена на кожному кроці.

### Self-Consistency

Спираючись на ідею Chain of Thought, техніка Self-Consistency спрямована на покращення надійності міркування шляхом використання ймовірнісної природи мовних моделей. Замість покладання на єдиний жадний шлях міркування (як у базовому CoT), Self-Consistency генерує множинні різноманітні шляхи міркування для однієї та тієї ж проблеми, а потім вибирає найбільш послідовну відповідь серед них.

Self-Consistency включає три основні кроки:

1. **Генерування різноманітних шляхів міркування**: Один і той же промпт (часто CoT промпт) відправляється LLM множину разів. Використовуючи вищу настройку температури, модель спонукається досліджувати різні підходи до міркування та генерувати різноманітні покрокові пояснення.
2. **Видобування відповіді**: Остаточна відповідь видобувається з кожного з згенерованих шляхів міркування.
3. **Вибір найбільш поширеної відповіді**: Виконується голосування більшістю по видобутим відповідям. Відповідь, яка з'являється найчастіше серед різноманітних шляхів міркування, вибирається як остаточна, найбільш послідовна відповідь.

Цей підхід покращує точність та когерентність відповідей, особливо для завдань, де можуть існувати множинні валідні шляхи міркування або де модель може бути схильна до помилок у єдиній спробі. Перевага полягає у псевдо-ймовірнісній оцінці коректності відповіді, збільшуючи загальну точність. Однак значна вартість — необхідність запускати модель множину разів для одного й того ж запиту, що призводить до набагато вищих обчислювальних витрат та витрат.

- **Приклад (концептуальний)**:
  - **Промпт**: "Чи є твердження 'Всі птахи можуть літати' істинним або хибним? Поясни своє міркування."
  - **Запуск моделі 1 (висока темпер)**: Міркує про більшість птахів, що літають, робить висновок Істина.
  - **Запуск моделі 2 (висока темпер)**: Міркує про пінгвінів та страусів, робить висновок Хибність.
  - **Запуск моделі 3 (висока темпер)**: Міркує про птахів у загалі, коротко згадує виключення, робить висновок Істина.
  - **Результат Self-Consistency**: На основі голосування більшістю (Істина з'являється двічі), остаточна відповідь "Істина". (Примітка: більш складний підхід взважив би якість міркування).

### Step-Back промптинг

Step-back промптинг покращує міркування, спочатку спонукаючи мовну модель розглянути загальний принцип або концепцію, пов'язану з завданням, перед розглядом конкретних деталей. Відповідь на це більш широке питання потім використовується як контекст для вирішення первісної проблеми.

Цей процес дозволяє мовній моделі активувати релевантні фонові знання та ширші стратегії міркування. Сконцентруючись на основних принципах або абстракціях вищого рівня, модель може генерувати більш точні та проникливі відповіді, менш підверженні впливу поверхневих елементів. Первісне розглядання загальних факторів може забезпечити міцнішу основу для генерування конкретних творчих виходів. Step-back промптинг заохочує критичне мислення та застосування знань, потенційно пом'якшуючи упередження шляхом наголосу на загальних принципах.

- **Приклад**:
  - **Промпт 1 (Step-Back)**: "Які ключові фактори роблять хорошу детективну історію?"
  - **Відповідь моделі 1**: (Перераховує елементи, такі як хибні підказки, переконливий мотив, вадований протагоніст, логічні підказки, задовільна розв'язка).
  - **Промпт 2 (первісне завдання + контекст Step-Back)**: "Використовуючи ключові фактори хорошої детективної історії [вставте відповідь моделі 1 тут], напиши коротке резюме сюжету для нового детективного роману, дія якого розгортається в маленькому місті."

### Tree of Thoughts (ToT)

Tree of Thoughts (ToT) — це просунута техніка міркування, яка розширює метод Chain of Thought. Вона дозволяє мовній моделі досліджувати множинні шляхи міркування одночасно, замість дотримання єдиної лінійної прогресії. Ця техніка використовує деревоподібну структуру, де кожен вузол представляє "думку" — когерентну мовну послідовність, яка діє як проміжний крок. З кожного вузла модель може розгалужуватися, досліджуючи альтернативні шляхи міркування.

ToT особливо підходить для складних проблем, що вимагають дослідження, повернення назад або оцінки множинних можливостей перед отриманням рішення. Хоча більш обчислювально дорогий та складний для реалізації, ніж лінійний метод Chain of Thought, ToT може досягнути вищих результатів на завданнях, що вимагають обдуманого та дослідницького вирішення проблем. Він дозволяє агенту розглядати різноманітні перспективи та потенційно відновлюватися від початкових помилок шляхом дослідження альтернативних гілок у "дереві думок".

- **Приклад (концептуальний)**: Для складного завдання творчого письма, такого як "Розробіть три різні можливі закінчення для історії на основі цих сюжетних точок", ToT дозволив би моделі досліджувати окремі оповідні гілки від ключової поворотної точки, замість просто генерування одного лінійного продовження.

Ці техніки міркування та процесів мислення критично важливі для створення агентів, здатних справляти з завданнями, що виходять за межи простого видобування інформації або генерування тексту. Спонукаючи моделі розкривати своє міркування, розглядати множинні перспективи або відступати до загальних принципів, ми можемо значно покращити їхню здатність виконувати складні когнітивні завдання в агентних системах.

## Техніки дій та взаємодій

Інтелектуальні агенти мають здатність активно взаємодіяти зі своїм середовищем, виходячи за межи генерування тексту. Це включає використання інструментів, виконання зовнішніх функцій та участь у ітеративних циклах спостереження, міркування та дії. Цей розділ розглядає техніки промптингу, розроблені для забезпечення цих активних поведінок.

### Використання інструментів / Виклик функцій

Критично важливою здатністю для агента є використання зовнішніх інструментів або виклик функцій для виконання дій, що виходять за межи його внутрішніх можливостей. Ці дії можуть включати веб-пошук, доступ до баз даних, відправлення електронних листів, виконання обчислень або взаємодію із зовнішніми API. Ефективний промптинг для використання інструментів включає розробку промптів, які інструктують модель про підходящий час та методологію використання інструментів.

Сучасні мовні моделі часто проходять тонке налаштування для "виклику функцій" або "використання інструментів". Це дозволяє їм інтерпретувати описи доступних інструментів, включаючи їхню мету та параметри. При отриманні запиту користувача модель може визначити необхідність використання інструмента, ідентифікувати підходящий інструмент та відформатувати необхідні аргументи для його виклику. Модель не виконує інструмент безпосередньо. Замість цього вона генерує структурований вивід, звичайно у форматі JSON, що вказує інструмент та його параметри. Агентна система потім обробляє цей вивід, виконує інструмент та надає результат інструмента назад моделі, інтегруючи його у продовжуючу взаємодію.

- **Приклад**:
  У тебе є доступ до інструмента погоди, який може отримати поточну погоду для вказаного міста. Інструмент називається 'get_current_weather' та приймає параметр 'city' (рядок).

  Користувач: Яка сейчас погода в Лондоні?

  - **Очікуваний вивід моделі (виклик функції)**:
    ```json
    {
      "tool_code": "get_current_weather",
      "tool_name": "get_current_weather",
      "parameters": {
        "city": "London"
      }
    }
    ```

### ReAct (Reason & Act)

ReAct, скорочення від Reason and Act, — це парадигма промптингу, яка поєднує міркування у стилі Chain of Thought зі здатністю виконувати дії з використанням інструментів у змінній манері. ReAct імітує те, як працюють люди — ми вербально міркуємо та виконуємо дії для збирання додаткової інформації або просування до мети.

Патерн ReAct включає цикл:

1. **Думка**: Модель генерує мисленневий процес, пояснюючи своє поточне розуміння та план.
2. **Дія**: На основі думки модель вирішує виконати дію, часто використовуючи інструмент (наприклад, Пошук, Калькулятор, виклик API). Вона виводить назву інструмента та необхідний вхід.
3. **Спостереження**: Агентна система виконує інструмент та надає результат (Спостереження) назад моделі.
4. Цикл продовжується з генеруванням моделлю нової "Думки" на основі останнього "Спостереження", що призводить до подальших "Дій" та "Спостережень" до завершення завдання та виводу моделлю "Остаточної відповіді".

Цей змінний процес мислення та дії дозволяє агенту динамічно збирати інформацію, реагувати на виходи інструментів та уточнювати свій підхід, роблячи його особливо ефективним для завдань, що вимагають взаємодії з динамічними середовищами або зовнішніми джерелами знань.

- **Приклад (ілюстративний слід ReAct)**:
  Користувач: Яка столиця Франції та яке її поточне населення?

  Думка: Користувач запитує дві частини інформації: столицю Франції та її населення. Я можу використовувати інструмент пошуку для пошуку цієї інформації. Почну з підтвердження столиці, хоча я, ймовірно, знаю її.
  Дія: Search({"query": "столиця Франції"})
  Спостереження: Париж

  Думка: Добре, столиця — Париж. Тепер мені потрібно знайти население Парижа.
  Дія: Search({"query": "поточне населення Парижа"})
  Спостереження: Население Парижа оцінювалось приблизно в 2,1 мільйона людей у 2023 році.

  Думка: Я знайшов обидві частини інформації. Тепер я можу надати остаточну відповідь користувачу.
  Остаточна відповідь: Столиця Франції — Париж, і її оціночне население у 2023 році становило близько 2,1 мільйона людей.

Ці техніки життєво важливі для створення агентів, які можуть активно взаємодіяти зі світом, отримувати інформацію в реальному часі та виконувати завдання, що вимагають взаємодії із зовнішніми системами.

## Просунуті техніки

Крім фундаментальних, структурних та міркуючих патернів, існує кілька інших технік промптингу, які можуть додатково покращити можливості та ефективність агентних систем. Вони варіюються від використання ШІ для оптимізації промптів до включення зовнішніх знань та адаптації відповідей на основі характеристик користувача.

### Автоматична промптинг-інженерія (APE)

Визнаючи, що створення ефективних промптів може бути складним та ітеративним процесом, Автоматична промптинг-інженерія (APE) досліджує використання самих мовних моделей для генерування, оцінки та вдосконалення промптів. Цей метод спрямований на автоматизацію процесу написання промптів, потенційно покращуючи продуктивність моделі без вимоги обширних людських зусиль у дизайні промптів.

Загальна ідея полягає у тому, щоб мати "мета-модель" або процес, який бере опис завдання та генерує множинні кандидати промптів. Ці промпти потім оцінюються на основі якості виводу, який вони виробляють на даному наборі вхідних даних (можливо, використовуючи метрики, такі як BLEU або ROUGE, або оцінку людиною). Найбільш продуктивні промпти можуть бути вибрані, потенційно додатково вдосконалені та використані для цільового завдання. Використання LLM для генерування варіацій запиту користувача для навчання чат-бота є прикладом цього.

- **Приклад (концептуальний)**: Розробник надає опис: "Мені потрібен промпт, який може видобути дату та відправника з електронного листа." Система APE генерує кілька кандидатів промптів. Вони тестуються на зразках листів, і промпт, який послідовно видобуває правильну інформацію, вибирається.

Інша потужна техніка оптимізації промптів, особливо просувається фреймворком DSPy, включає розглядання промптів не як статичного тексту, але як програмних модулів, які можуть бути автоматично оптимізовані. Цей підхід виходить за межи ручного методу проб і помилок до більш систематичної, керованої даними методології.

Ядро цієї техніки спирається на два ключові компоненти:

1. **Goldset (або високоякісний набір даних)**: Це репрезентативний набір високоякісних пар вхід-вихід. Він служить "золотим стандартом", який визначає, як виглядає успішна відповідь для даного завдання.
2. **Об'єктивна функція (або метрика оцінки)**: Це функція, яка автоматично оцінює вивід LLM проти відповідного "золотого" виводу з набору даних. Вона повертає оцінку, що вказує на якість, точність або коректність відповіді.

Використовуючи ці компоненти, оптимізатор, такий як байесовський оптимізатор, систематично вдосконалює промпт. Цей процес зазвичай включає дві основні стратегії, які можуть використовуватися незалежно або спільно:

- **Оптимізація few-shot прикладів**: Замість того щоб розробник вручну вибирав приклади для few-shot промпта, оптимізатор програмно вибирає різні комбінації прикладів із goldset. Потім він тестує ці комбінації для ідентифікації конкретного набору прикладів, який найбільш ефективно спрямовує модель до генерування бажаних виходів.
- **Оптимізація інструкційного промпта**: У цьому підході оптимізатор автоматично вдосконалює основні інструкції промпта. Він використовує LLM як "мета-модель" для ітеративної зміни та переформулювання тексту промпта — коригуючи формулювання, тон або структуру — для виявлення того, яке формулювання дає найвищі оцінки від об'єктивної функції.

Кінцева мета для обох стратегій — максимізувати оцінки від об'єктивної функції, ефективно "навчаючи" промпт виробляти результати, які послідовно ближче до високоякісного goldset. Поєднуючи ці два підходи, система може одночасно оптимізувати які інструкції давати моделі та які приклади їй показувати, призводячи до висо кого ефективного та надійного промпта, який машинно-оптимізований для конкретного завдання.

### Ітеративний промптинг / Вдосконалення

Ця техніка включає починання з простого, базового промпта та потім ітеративне його вдосконалення на основі першочергових ответов моделі. Якщо вивід моделі не зовсім правильний, ви аналізуєте недоліки та модифікуєте промпт для їхного усунення. Це менш автоматизований процес (на відміну від APE) та більш керований людиною ітеративний цикл дизайну.

- **Приклад**:
  - **Спроба 1**: "Напиши опис продукту для нового типу кавомашини." (Результат занадто загальний).
  - **Спроба 2**: "Напиши опис продукту для нового типу кавомашини. Підкресли її швидкість та легкість очищення." (Результат кращий, але не вистачає деталей).
  - **Спроба 3**: "Напиши опис продукту для 'SpeedClean Coffee Pro'. Підкресли її здатність варити каву менше ніж за 2 хвилини та її самоочищуючийся цикл. Ориєнтуйся на зайнятих професіоналів." (Результат набагато ближче до бажаного).

### Надання негативних прикладів

Хоча принцип "Інструкції замість обмежень" загалом вірний, є ситуації, де надання негативних прикладів може бути корисним, хоча з обережністю. Негативний приклад показує моделі вхід та небажаний вихід, або вхід та вихід, який не повинен бути генерований. Це може допомогти прояснити межі або запобігти певним типам неправильних ответов.

- **Приклад**:
  Згенеруй список популярних туристичних визначних пам'яток у Парижі. НЕ включай Айфелеву вежу.

  Приклад того, чого НЕ робити:
  Вхід: Перерахуй популярні визначні пам'ятки у Парижі.
  Вихід: Айфелева вежа, Лувр, Собор Паризької Богоматері.

### Використання аналогій

Формулювання завдання з використанням аналогії іноді може допомогти моделі зрозуміти бажаний вивід або процес, пов'язавши його з чимось знайомим. Це може бути особливо корисним для творчих завдань або пояснення складних ролей.

- **Приклад**:
  Діяй як "шеф-кухар даних". Візьми сирі інгредієнти (точки даних) та приготуй "блюдо-резюме" (звіт), яке підкреслює ключові смаки (тренди) для ділової аудиторії.

### Факторизоване пізнання / Декомпозиція

Для дуже складних завдань може бути ефективним розбити загальну мету на менші, керовані підзавдання та промптити модель окремо для кожного підзавдання. Результати підзавдань потім поєднуються для досягнення остаточного результату. Це пов'язано з ланцюжком промптів та плануванням, але підкреслює обдумане розбиття проблеми.

- **Приклад**: Для написання дослідницької роботи:
  - Промпт 1: "Згенеруй детальний план для статті про вплив ШІ на ринок праці."
  - Промпт 2: "Напиши розділ вступу на основі цього плану: [вставте план введення]."
  - Промпт 3: "Напиши розділ 'Вплив на працівників розумової праці' на основі цього плану: [вставте розділ плану]." (Повторіть для інших розділів).
  - Промпт N: "Об'єднай ці розділи та напиши висновок."

### Retrieval Augmented Generation (RAG)

RAG — це потужна техніка, яка покращує мовні моделі, надаючи їм доступ до зовнішної, актуальної або доменно-специфічної інформації під час процесу промптингу. Коли користувач ставить питання, система спочатку видобуває релевантні документи або дані з бази знань (наприклад, бази даних, набору документів, мережі). Ця видобута інформація потім включається в промпт як контекст, дозволяючи мовній моделі генерувати відповідь, засновану на цих зовнішніх знаннях. Це пом'якшує проблеми, такі як галюцинації, та надає доступ до інформації, на якій модель не була навчена або яка дуже свіжа. Це ключовий патерн для агентних систем, які повинні працювати з динамічною або власною інформацією.

- **Приклад**:
  - **Запит користувача**: "Які нові функції у останній версії Python-бібліотеки 'X'?"
  - **Дія системи**: Пошук у базі даних документації "Python бібліотека X нові функції".
  - **Промпт для LLM**: "На основі наступних фрагментів документації: [вставте видобутий текст], поясни нові функції у останній версії Python-бібліотеки 'X'."

### Паттерн персони (користувацька персона)

У той час як ролевий промптинг призначає персону моделі, паттерн персони включає опис користувача або цільової аудиторії для виводу моделі. Це допомагає моделі адаптувати свою відповідь з точки зору мови, складності, тону та типу інформації, яку вона надає.

- **Приклад**:
  Ти пояснюєш квантову фізику. Цільова аудиторія — старшокласник без попередніх знань з предмета. Поясни це просто та використовуй аналогії, які вони можуть зрозуміти.

  Поясни квантову фізику: [Вставте запит базового пояснення]

Ці просунуті та додаткові техніки надають додаткові інструменти для промптинг-інженерів для оптимізації поведінки моделі, інтеграції зовнішної інформації та адаптації взаємодій для конкретних користувачів та завдань в агентних робочих процесах.

## Використання Google Gems

"Gems" від Google (див. Рис. 1) представляють користувацьку налаштовувану функцію в архітектурі великих мовних моделей. Кожен "Gem" функціонує як спеціалізований екземпляр основного ШІ Gemini, адаптований для конкретних, повторюваних завдань. Користувачі створюють Gem, надаючи йому набір явних інструкцій, які встановлюють його операційні параметри. Цей початковий набір інструкцій визначає призначену мету Gem, стиль відповіді та область знань. Базова модель розроблена для послідовного дотримання цих попередньо визначених директив протягом розмови.

Це дозволяє створювати висо кo-спеціалізованих ШІ-агентів для сфокусованих застосувань. Наприклад, Gem може бути налаштований для функціонування як інтерпретатор коду, який посилається лише на визначені бібліотеки програмування. Інший може бути інструктований аналізувати набори даних, генеруючи резюме без спекулятивних коментарів. Різний Gem може служити перекладачем, дотримуючись певного формального посібника стилю. Цей процес створює постійний, специфічний для завдання контекст для штучного інтелекту.

Отже, користувач уникає необхідності переустановлювати один і той же контекстуальний інформацію з кожним новим запитом. Ця методологія зменшує розмовну надмірність та покращує ефективність виконання завдань. Результуючі взаємодії більш сфокусовані, надаючи виходи, які послідовно відповідають першочерговим вимогам користувача. Ця структура дозволяє застосовувати тонке, постійне користувацьке керівництво до моделі ШІ загального призначення. Зрештою, Gems дозволяють перехід від взаємодії загального призначення до спеціалізованих, попередньо визначених функціональностей ШІ.

![][image1]

_Рис.1: Приклад використання Google Gem._

[image1]: ../Assets/appendix-a-image1.png

## Використання LLM для покращення промптів (Мета-підхід)

Ми дослідили множинні техніки для створення ефективних промптів, підкреслюючи ясність, структуру та надання контексту або прикладів. Однак цей процес може бути ітеративним та іноді складним. Що робити, якщо б ми могли використовувати саму потужність великих мовних моделей, таких як Gemini, щоб допомогти нам покращити наші промпти? Це суть використання LLM для вдосконалення промптів — "мета"-застосування, де ШІ допомагає в оптимізації інструкцій, наданих ШІ.

Ця здатність особливо "крута", оскільки вона представляє форму самопокращення ШІ або, щонайменше, ШІ-асистованого людського покращення у взаємодії з ШІ. Замість покладання виключно на людську інтуїцію та метод проб і помилок, ми можемо використовувати розуміння LLM мови, патернів та навіть поширених підводних каменів промптингу для отримання пропозицій щодо покращення наших промптів. Це перетворює LLM на колаборативного партнера в процесі промптинг-інженерії.

Як це працює на практиці? Ви можете надати мовній моделі існуючий промпт, який ви намагаєтесь покращити, разом із завданням, яке ви хочете виконати, і можливо навіть приклади виводу, який ви отримуєте зараз (та чому він не відповідає вашим очікуванням). Потім ви промптите LLM проаналізувати промпт та запропонувати покращення.

Модель, як-то Gemini, з його сильними здатностями до міркування та генерування мови, може аналізувати ваш існуючий промпт на потенційні площі неоднозначності, відсутність специфічності або неефективне формулювання. Вона може запропонувати включення технік, які ми обговорювали, таких як додавання роздільників, прояснення бажаного формату виводу, запропонування більш ефективної персони або рекомендація включення few-shot прикладів.

Переваги цього мета-промптингу підходу включають:

- **Прискорена ітерація**: Отримання пропозицій щодо покращення набагато швидше, ніж чистий ручний метод проб і помилок.
- **Ідентифікація сліпих плям**: LLM може помітити неоднозначності або потенційні неправильні інтерпретації у вашому промпті, які ви пропустили.
- **Можливість навчання**: Бачачи типи пропозицій, які робить LLM, ви можете дізнатися більше про те, що робить промпти ефективними, та покращити свої власні навички промптинг-інженерії.
- **Масштабованість**: Потенційно автоматизувати частини процесу оптимізації промптів, особливо при роботі з великою кількістю промптів.

Важливо відзначити, що пропозиції LLM не завжди ідеальні та повинні оцінюватись та тестуватись, як будь-який ручно створений промпт. Однак це надає потужну вихідну точку та може значно спростити процес вдосконалення.

- **Приклад промпта для вдосконалення**:
  Проаналізуй наступний промпт для мовної моделі та запропонуй способи його покращення для послідовного видобування основної теми та ключових сутностей (люди, організації, локації) з новинних статей. Поточний промпт іноді пропускає сутності або неправильно визначає основну тему.

  Існуючий промпт:
  "Підсумуй основні пункти та перерахуй важливі імена та місця з цієї статті: [вставте текст статті]"

  Пропозиції щодо покращення:

У цьому прикладі ми використовуємо LLM для критики та покращення іншого промпта. Ця мета-рівнева взаємодія демонструє гнучкість та потужність цих моделей, дозволяючи нам створювати більш ефективні агентні системи шляхом спочатку оптимізації фундаментальних інструкцій, які вони отримують. Це захоплюючий цикл, де ШІ допомагає нам краще говорити з ШІ.

## Промптинг для специфічних завдань

Хоча техніки, обговорені до цих пір, широко застосовні, деякі завдання отримують користь від специфічних міркувань промптингу. Вони особливо релевантні в області кодування та мультимодальних вхідних даних.

### Промптинг кодування

Мовні моделі, особливо ті, які навчені на великих наборах даних кодування, можуть бути потужними помічниками для розробників. Промптинг для кодування включає використання LLM для генерування, пояснення, перекладу або налагодження кодування. Існують різні випадки використання:

- **Промпти для написання кодування**: Запит моделі генерувати фрагменти кодування або функції на основі опису бажаної функціональності.

  - **Приклад**: "Напиши Python-функцію, яка приймає список чисел та повертає середнє значення."

- **Промпти для пояснення кодування**: Надання фрагмента кодування та запит моделі пояснити, що він робить, побудовано або у резюме.

  - **Приклад**: "Поясни наступний JavaScript-фрагмент кодування: [вставте кодування]."

- **Промпти для перекладу кодування**: Запит моделі перевести кодування з однієї мови програмування на іншу.

  - **Приклад**: "Переведи наступне Java-кодування на C++: [вставте кодування]."

- **Промпти для налагодження та перегляду кодування**: Надання кодування, яке має помилку або може бути покращено, та запит моделі ідентифікувати проблеми, запропонувати виправлення або надати пропозиції щодо рефакторингу.
  - **Приклад**: "Наступне Python-кодування дає 'NameError'. Що не так та як це можна виправити? [вставте кодування та трасування]."

Ефективний промптинг кодування часто вимагає надання достатнього контексту, вказування бажаної мови та версії, та ясності щодо функціональності або проблеми.

### Мультимодальний промптинг

Хоча фокус цього додатку та більшість поточної взаємодії з LLM базуються на тексті, область швидко рухається до мультимодальних моделей, які можуть обробляти та генерувати інформацію через різні модальності (текст, зображення, аудіо, відео тощо). Мультимодальний промптинг включає використання комбінації вхідних даних для спрямування моделі. Це відноситься до використання множинних форматів вхідних даних замість лише тексту.

- **Приклад**: Надання зображення діаграми та запит моделі пояснити процес, показаний на діаграмі (Вхід зображення + Текстовий промпт). Або надання зображення та запит моделі генерувати описовий підпис (Вхід зображення + Текстовий промпт → Текстовий вихід).

Оскільки мультимодальні можливості стають більш складними, техніки промптингу будуть еволюціонувати для ефективного використання цих комбінованих вхідних та вихідних даних.

## Найкращі практики та експерименти

Становлення кваліфікованим промптинг-інженером — це ітеративний процес, який включає постійне навчання та експерименти. Кілька цінних найкращих практик варто повторити та підкреслити:

- **Надавай приклади**: Надання one-shot або few-shot прикладів — один із найбільш ефективних способів спрямування моделі.
- **Дизайн з простотою**: Тримай свої промпти стислими, ясними та легкими для розуміння. Уникай непотрібного жаргону або надто складних формулювань.
- **Будь специфічним щодо виводу**: Чітко визначи бажаний формат, довжину, стиль та вміст відповіді моделі.
- **Використовуй інструкції замість обмежень**: Зосередь на тому, щоб сказати моделі, що ти хочеш, щоб вона робила, а не на тому, чого ти не хочеш, щоб вона робила.
- **Контролюй максимальну довжину токенів**: Використовуй конфігурації моделі або явні інструкції промпта для керування довжиною генерованого виводу.
- **Використовуй змінні в промптах**: Для промптів, використовуваних в застосуваннях, використовуй змінні, щоб зробити їх динамічними та переиспользуємими, уникаючи жорсткого кодування конкретних значень.
- **Експериментуй з форматами вводу та стилями письма**: Спробуй різні способи формулювання свого промпта (питання, твердження, інструкція) та експериментуй з різними тонами або стилями, щоб побачити, що дає кращі результати.
- **Для few-shot промптингу з завданнями класифікації змішуй класи**: Рандомізуй порядок прикладів з різних категорій, щоб запобігти переоснащенню.
- **Адаптуйся до оновлень моделі**: Мовні моделі постійно оновлюються. Будь готовий тестувати існуючі промпти на нових версіях моделі та коригувати їх для використання нових можливостей або збереження продуктивності.
- **Експериментуй з форматами виводу**: Особливо для некреативних завдань експериментуй з запитом структурованого виводу, такого як JSON або XML.
- **Експериментуй спільно з іншими промптинг-інженерами**: Співробітництво з іншими може надати різні перспективи та призвести до виявлення більш ефективних промптів.
- **Найкращі практики CoT**: Пам'ятай специфічні практики для Chain of Thought, такі як розміщення відповіді після міркування та встановлення температури на 0 для завдань з єдиною правильною відповіддю.
- **Документуй різні спроби промптів**: Це критично важливо для відслідковування того, що працює, що не працює та чому. Підтримуй структурований запис своїх промптів, конфігурацій та результатів.
- **Зберігай промпти в кодових базах**: При інтеграції промптів в застосування зберігай їх в окремих, добре організованих файлах для більш легкого обслуговування та контролю версій.
- **Покладайся на автоматизовані тести та оцінку**: Для виробничих систем впровадж автоматизовані тести та процедури оцінки для моніторингу продуктивності промптів та забезпечення узагальнення на нові дані.

Промптинг-інженерія — це навичка, яка покращується з практикою. Застосовуючи ці принципи та техніки та підтримуючи систематичний підхід до експериментів та документації, ти можеш значно покращити свою здатність створювати ефективні агентні системи.

## Висновок

Цей додаток надає всеосяжний огляд промптингу, перекреслюючи його як дисциплінувану інженерну практику, а не просто акт задавання питань. Його центральна мета — продемонструвати, як трансформувати мовні моделі загального призначення в спеціалізовані, надійні та високоспроможні інструменти для конкретних завдань. Шлях починається з неповінних фундаментальних принципів, таких як ясність, стислість та ітеративні експерименти, які є каменем в основі ефективного спілкування з ШІ. Ці принципи критично важливі, оскільки вони зменшують притаманну природній мові неоднозначність, допомагаючи спрямувати ймовірнісні виходи моделі до єдиної, правильної цілі. Спираючись на цю основу, базові техніки, такі як zero-shot, one-shot та few-shot промптинг, служать основними методами для демонстрації очікуваної поведінки через приклади. Ці методи надають різні рівні контекстуального керівництва, потужно формуючи стиль відповіді моделі, тон та формат. Крім простих прикладів, структурування промптів з явними ролями, системними інструкціями та чіткими роздільниками надає суттєвий архітектурний шар для тонкого контролю над моделлю.

Важливість цих технік стає першорядною в контексті створення автономних агентів, де вони забезпечують контроль та надійність, необхідні для складних, багатокрокових операцій. Щоб агент ефективно створював та виконував план, він повинен використовувати просунуті патерни міркування, такі як Chain of Thought та Tree of Thoughts. Ці складні методи змушують модель екстеріоризувати свої логічні кроки, систематично розбиваючи складні цілі на послідовність керованих підзавдань. Операційна надійність всієї агентної системи залежить від передбачуваності кожного компонентного виводу. Саме тому запит структурованих даних, таких як JSON, та програмна їх валідація за допомогою інструментів, таких як Pydantic, є не просто зручністю, але абсолютною необхідністю для надійної автоматизації. Без цієї дисципліни внутрішні когнітивні компоненти агента не можуть надійно спілкуватися, що призводить до катастрофічних збоїв в автоматизованому робочому процесі. Зрештою, ці техніки структурування та міркування успішно конвертують ймовірнісну генерацію тексту моделі в детермінований та вірогідний когнітивний двигун для агента.

Крім того, ці промпти надають агенту критично важливу здатність сприймати та впливати на своє середовище, подолаючи розрив між цифровою думкою та взаємодією з реальним світом. Орієнтовані на дію фреймворки, такі як ReAct та нативний виклик функцій, є життєво важливими механізмами, які служать руками агента, дозволяючи йому використовувати інструменти, запитувати API та маніпулювати даними. Паралельно техніки, такі як Retrieval Augmented Generation (RAG) та ширша дисципліна контекстної інженерії, функціонують як чуття агента. Вони активно видобувають релевантну, актуальну інформацію з зовнішніх баз знань, забезпечуючи, що рішення агента базуються на поточній, фактичній реальності. Ця критично важлива здатність запобігає роботі агента у вакуумі, де він був би обмежений своїми статичними та потенційно застарілими даними навчання. Оволодіння цим повним спектром промптингу є, таким чином, визначальною навичкою, яка піднімає мовну модель загального призначення від простого генератора тексту до справді складного агента, здатного виконувати складні завдання з автономністю, обізнаністю та інтелектом.

## Посилання

Ось список ресурсів для подальшого читання та глибшого вивчення технік промптинг-інженерії:

1. [Prompt Engineering](https://www.kaggle.com/whitepaper-prompt-engineering)
2. [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)
3. [Self-Consistency Improves Chain of Thought Reasoning in Language Models](https://arxiv.org/pdf/2203.11171)
4. [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)
5. [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/pdf/2305.10601)
6. [Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models](https://arxiv.org/abs/2310.06117)
7. DSPy: Programming—not prompting—Foundation Models https://github.com/stanfordnlp/dspy

---

## Навігація

**Назад:** [Розділ 21. Дослідження та відкриття](../Частина%204/Розділ%2021.%20Дослідження%20та%20відкриття.md)<br>
**Вперед:** [Додаток B. Агентні взаємодії ШІ від графічного інтерфейсу до реального світу](Додаток%20B.%20Агентні%20взаємодії%20ШІ%20від%20графічного%20інтерфейсу%20до%20реального%20світу.md)
